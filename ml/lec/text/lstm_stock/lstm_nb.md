
## LSTMã‚’ä½¿ã£ãŸæ ªä¾¡äºˆæ¸¬

LSTMã¯æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ã®ãŸã‚ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€ã‚ã‚‹å ´æ‰€ã®æ°—æ¸©ã‚„ã€æ¥å®¢æ•°ã€å•†å“ã®ä¾¡æ ¼ãªã©å¤šå²ã«ã‚ãŸã‚Šã¾ã™ãŒã€æœ€ã‚‚ãƒ‡ãƒ¼ã‚¿ã‚’å…¥æ‰‹ã—ã‚„ã™ã„æ ªä¾¡ã‚’LSTMã§äºˆæ¸¬ã‚’è¡Œã£ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚

ãŸã ã—ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã¯ã‚ãã¾ã§ã‚‚å¾—ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å†…ã§ã—ã‹äºˆæ¸¬ã™ã‚‹äº‹ãŒå‡ºæ¥ãšã€æƒ³å®šå¤–ã®çŠ¶æ³ã«ãªã£ãŸå ´åˆã€ãã®ãƒ¢ãƒ‡ãƒ«ã¯ã»ã¼æ„å‘³ã‚’ãªã—ã¾ã›ã‚“ã€‚

ä¾‹ãˆã°ã€ã‚³ãƒ­ãƒŠã‚·ãƒ§ãƒƒã‚¯å‰ã®1å¹´å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã‚‚ã€ã‚³ãƒ­ãƒŠã‚·ãƒ§ãƒƒã‚¯ã‚’äºˆæ¸¬ã™ã‚‹äº‹ã¯å‡ºæ¥ã¾ã›ã‚“ã€‚

æ ªä¾¡ã®å½¢æˆã¯ãƒ©ãƒ³ãƒ€ãƒ ãªè¦ç´ ã‚‚ã‚ã‚Šã€LSTMã§æœªæ¥ã‚’äºˆæ¸¬ã™ã‚‹ã®ã¯é›£ã—ã„ã¨ã¯æ€ã„ã¾ã™ãŒã€LSTMã«æ…£ã‚Œã‚‹ãŸã‚ã«ã‚„ã£ã¦ã¿ã‚ˆã†ã¨æ€ã„ã¾ã™ã€‚

### github
- jupyter notebookå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯[ã“ã¡ã‚‰](https://github.com/hiroshi0530/wa-src/tree/master/ml/lec/text/lstm_stock/lstm_nb.ipynb)

### google colaboratory
- google colaboratory ã§å®Ÿè¡Œã™ã‚‹å ´åˆã¯[ã“ã¡ã‚‰](https://colab.research.google.com/github/hiroshi0530/wa-src/tree/master/ml/lec/text/lstm_stock/lstm_nb.ipynb)

### ç­†è€…ã®ç’°å¢ƒ
ç­†è€…ã®OSã¯macOSã§ã™ã€‚Linuxã‚„Unixã®ã‚³ãƒãƒ³ãƒ‰ã¨ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒç•°ãªã‚Šã¾ã™ã€‚


```python
!sw_vers
```

    ProductName:	Mac OS X
    ProductVersion:	10.14.6
    BuildVersion:	18G6020



```python
!python -V
```

    Python 3.7.3


åŸºæœ¬çš„ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨kerasã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã—ã¦ãŠãã¾ã™ã€‚


```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

import matplotlib
import matplotlib.pyplot as plt
import scipy
import numpy as np
import pandas as pd

import tensorflow as tf
from tensorflow import keras

print('matplotlib version :', matplotlib.__version__)
print('scipy version :', scipy.__version__)
print('numpy version :', np.__version__)
print('tensorflow version : ', tf.__version__)
print('keras version : ', keras.__version__)
```

    matplotlib version : 3.0.3
    scipy version : 1.4.1
    numpy version : 1.19.4
    tensorflow version :  2.1.0
    keras version :  2.2.4-tf



```python

```


```python

```

## ãƒ‡ãƒ¼ã‚¿ã®å–å¾—

ä»Šå›ã¯æ—¥çµŒå¹³å‡ã¨ã‚¢ãƒ¡ãƒªã‚«ã®S&P500ã®æ ªä¾¡ã®ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ãã‚Œãã‚Œä»¥ä¸‹ã®ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚

### æ—¥çµŒå¹³å‡ã®ãƒ‡ãƒ¼ã‚¿

- https://indexes.nikkei.co.jp/nkave/index?type=download

### SP500ã®ãƒ‡ãƒ¼ã‚¿

- https://kabuoji3.com/stock/download.php


## ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
ã¾ãšæœ€åˆã«æ—¥çµŒã®ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¦ã¿ã¾ã™ã€‚


```python
!ls 
```

    lstm_nb.ipynb   lstm_nb.py      nikkei.csv      sp500_2019.csv
    lstm_nb.md      [34mlstm_nb_files[m[m   nikkei_utf8.csv sp500_2020.csv



```bash
%%bash
head nikkei.csv
```

    ï¿½fï¿½[ï¿½^ï¿½ï¿½ï¿½t,ï¿½Iï¿½l,ï¿½nï¿½l,ï¿½ï¿½ï¿½l,ï¿½ï¿½ï¿½l
    "2017/01/04","19594.16","19298.68","19594.16","19277.93"
    "2017/01/05","19520.69","19602.10","19615.40","19473.28"
    "2017/01/06","19454.33","19393.55","19472.37","19354.44"
    "2017/01/10","19301.44","19414.83","19484.90","19255.35"
    "2017/01/11","19364.67","19358.64","19402.17","19325.46"
    "2017/01/12","19134.70","19300.19","19300.19","19069.02"
    "2017/01/13","19287.28","19174.97","19299.36","19156.93"
    "2017/01/16","19095.24","19219.13","19255.41","19061.27"
    "2017/01/17","18813.53","19038.45","19043.91","18812.86"


æ–‡å­—ã‚³ãƒ¼ãƒ‰ãŒshift-jisã«ãªã£ã¦ã„ã‚‹ã®ã§ã€utf-8ã«ç›´ã—ã¾ã™ã€‚


```bash
%%bash
nkf --guess nikkei.csv
```

    Shift_JIS (CRLF)



```bash
%%bash
nkf -w nikkei.csv > nikkei_utf8.csv
```


```bash
%%bash
head nikkei_utf8.csv
```

    ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜,çµ‚å€¤,å§‹å€¤,é«˜å€¤,å®‰å€¤
    "2017/01/04","19594.16","19298.68","19594.16","19277.93"
    "2017/01/05","19520.69","19602.10","19615.40","19473.28"
    "2017/01/06","19454.33","19393.55","19472.37","19354.44"
    "2017/01/10","19301.44","19414.83","19484.90","19255.35"
    "2017/01/11","19364.67","19358.64","19402.17","19325.46"
    "2017/01/12","19134.70","19300.19","19300.19","19069.02"
    "2017/01/13","19287.28","19174.97","19299.36","19156.93"
    "2017/01/16","19095.24","19219.13","19255.41","19061.27"
    "2017/01/17","18813.53","19038.45","19043.91","18812.86"


å•é¡Œãªã„ã‚ˆã†ãªã®ã§ã€pandasã§èª­ã¿è¾¼ã¿ã¾ã™ã€‚


```python
df = pd.read_csv('nikkei_utf8.csv')
```


```python
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜</th>
      <th>çµ‚å€¤</th>
      <th>å§‹å€¤</th>
      <th>é«˜å€¤</th>
      <th>å®‰å€¤</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2017/01/04</td>
      <td>19594.16</td>
      <td>19298.68</td>
      <td>19594.16</td>
      <td>19277.93</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2017/01/05</td>
      <td>19520.69</td>
      <td>19602.10</td>
      <td>19615.40</td>
      <td>19473.28</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2017/01/06</td>
      <td>19454.33</td>
      <td>19393.55</td>
      <td>19472.37</td>
      <td>19354.44</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2017/01/10</td>
      <td>19301.44</td>
      <td>19414.83</td>
      <td>19484.90</td>
      <td>19255.35</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2017/01/11</td>
      <td>19364.67</td>
      <td>19358.64</td>
      <td>19402.17</td>
      <td>19325.46</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.tail()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜</th>
      <th>çµ‚å€¤</th>
      <th>å§‹å€¤</th>
      <th>é«˜å€¤</th>
      <th>å®‰å€¤</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>971</th>
      <td>2020/12/24</td>
      <td>26668.35</td>
      <td>26635.11</td>
      <td>26764.53</td>
      <td>26605.26</td>
    </tr>
    <tr>
      <th>972</th>
      <td>2020/12/25</td>
      <td>26656.61</td>
      <td>26708.10</td>
      <td>26716.61</td>
      <td>26638.28</td>
    </tr>
    <tr>
      <th>973</th>
      <td>2020/12/28</td>
      <td>26854.03</td>
      <td>26691.29</td>
      <td>26854.03</td>
      <td>26664.60</td>
    </tr>
    <tr>
      <th>974</th>
      <td>2020/12/29</td>
      <td>27568.15</td>
      <td>26936.38</td>
      <td>27602.52</td>
      <td>26921.14</td>
    </tr>
    <tr>
      <th>975</th>
      <td>æœ¬è³‡æ–™ã¯æ—¥çµŒã®è‘—ä½œç‰©ã§ã‚ã‚Šã€æœ¬è³‡æ–™ã®å…¨éƒ¨åˆã¯ä¸€éƒ¨ã‚’ã€ã„ã‹ãªã‚‹å½¢å¼ã«ã‚ˆã£ã¦ã‚‚æ—¥çµŒã«ç„¡æ–­ã§è¤‡å†™ã€...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



æœ€å¾Œã®è¡Œã«è‘—ä½œæ¨©ã«é–¢ã™ã‚‹æ³¨æ„æ›¸ããŒã‚ã‚Šã¾ã™ãŒã€ã“ã‚Œã‚’å‰Šé™¤ã—ã¾ã™ã€‚è¤‡å†™ã‚„æµå¸ƒã¯è¡Œã„ã¾ã›ã‚“ã€‚


```python
df.drop(index=975, inplace=True)
```


```python
df.tail()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜</th>
      <th>çµ‚å€¤</th>
      <th>å§‹å€¤</th>
      <th>é«˜å€¤</th>
      <th>å®‰å€¤</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>970</th>
      <td>2020/12/23</td>
      <td>26524.79</td>
      <td>26580.43</td>
      <td>26585.21</td>
      <td>26414.74</td>
    </tr>
    <tr>
      <th>971</th>
      <td>2020/12/24</td>
      <td>26668.35</td>
      <td>26635.11</td>
      <td>26764.53</td>
      <td>26605.26</td>
    </tr>
    <tr>
      <th>972</th>
      <td>2020/12/25</td>
      <td>26656.61</td>
      <td>26708.10</td>
      <td>26716.61</td>
      <td>26638.28</td>
    </tr>
    <tr>
      <th>973</th>
      <td>2020/12/28</td>
      <td>26854.03</td>
      <td>26691.29</td>
      <td>26854.03</td>
      <td>26664.60</td>
    </tr>
    <tr>
      <th>974</th>
      <td>2020/12/29</td>
      <td>27568.15</td>
      <td>26936.38</td>
      <td>27602.52</td>
      <td>26921.14</td>
    </tr>
  </tbody>
</table>
</div>



ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã—ã¦ã¿ã¾ã™ã€‚ã‚³ãƒ­ãƒŠã‚·ãƒ§ãƒƒã‚¯ã§å¤§ããã¸ã“ã‚“ã§ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ãŒã€2020å¹´ã®å¹´æœ«ã®æ™‚ç‚¹ã§ã¯é‡‘èç·©å’Œã®å½±éŸ¿ã‚’å—ã‘ã¦å¤§å¹…ã«ä¸ŠãŒã£ã¦ã„ã¾ã™ã€‚


```python
ticks = 10
xticks = ticks * 5 

plt.plot(df['ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜'][::ticks], df['çµ‚å€¤'][::ticks], label='nikkei stock')
plt.grid()
plt.legend()
plt.xticks(df['ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜'][::xticks], rotation=60)
plt.show()
```


![svg](lstm_nb_files/lstm_nb_22_0.svg)


## ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™

kerasã«æŠ•å…¥ã™ã‚‹ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ãˆã¾ã™ã€‚


```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM

NUM_LSTM = 20

x = np.array((df['ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜']))
y = np.array((df['çµ‚å€¤']))



# x = np.linspace(0, 5 * np.pi, 200)
# y = np.exp(-x / 5) * (np.cos(x))



n = len(y) - NUM_LSTM
l_x = np.zeros((n, NUM_LSTM))
l_y = np.zeros((n, NUM_LSTM))
for i in range(0, n):
  l_x[i] = y[i: i + NUM_LSTM]
  l_y[i] = y[i + 1: i + NUM_LSTM + 1]

l_x = l_x.reshape(n, NUM_LSTM, 1)
l_y = l_y.reshape(n, NUM_LSTM, 1)
```


```python
print('shape : ', x.shape)
print('ndim : ', x.ndim)
print('data : ', x[:10])
```

    shape :  (975,)
    ndim :  1
    data :  ['2017/01/04' '2017/01/05' '2017/01/06' '2017/01/10' '2017/01/11'
     '2017/01/12' '2017/01/13' '2017/01/16' '2017/01/17' '2017/01/18']



```python
print('shape : ', y.shape)
print('ndim : ', y.ndim)
print('data : ', y[:10])
```

    shape :  (975,)
    ndim :  1
    data :  [19594.16 19520.69 19454.33 19301.44 19364.67 19134.7  19287.28 19095.24
     18813.53 18894.37]



```python
print(l_y.shape)
print(l_x.shape)
```

    (955, 20, 1)
    (955, 20, 1)


ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã‚’å®šç¾©ã™ã‚‹é–¢æ•°ã§ã™ã€‚


```python
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Activation

NUM_MIDDLE = 40 
NUM_MIDDLE_01 = 100
NUM_MIDDLE_02 = 120

def build_lstm_model():
  # LSTMãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®æ§‹ç¯‰
  model = Sequential()
  model.add(LSTM(NUM_MIDDLE, input_shape=(NUM_LSTM, 1), return_sequences=True))
  model.add(Dense(1, activation="linear"))
  model.compile(loss="mean_squared_error", optimizer="sgd")
  
  # LSTMãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®æ§‹ç¯‰
  # model = Sequential()
  # model.add(LSTM(NUM_MIDDLE_01, input_shape = (NUM_LSTM, 1), return_sequences=True))
  # model.add(Dropout(0.2))
  # model.add(LSTM(NUM_MIDDLE_02, return_sequences=True))
  # model.add(Dropout(0.2))
  # model.add(Dense(1))
  # model.add(Activation("linear"))
  # model.compile(loss="mse", optimizer='rmsprop')
  # model.compile(loss="mean_squared_error", optimizer="sgd")
  
  return model

model = build_lstm_model()
```

# è©³ç´°ã‚’ç¢ºèªã—ã¾ã™ã€‚


```python
print(model.summary())
```

    Model: "sequential_8"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    lstm_9 (LSTM)                (None, 20, 40)            6720      
    _________________________________________________________________
    dense_8 (Dense)              (None, 20, 1)             41        
    =================================================================
    Total params: 6,761
    Trainable params: 6,761
    Non-trainable params: 0
    _________________________________________________________________
    None



```python
batch_size = 20
epochs = 2000

# validation_split ã§æœ€å¾Œã®10ï¼…ã‚’æ¤œè¨¼ç”¨ã«åˆ©ç”¨ã—ã¾ã™
history = model.fit(l_x, l_y, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=0)
```


    ---------------------------------------------------------------------------

    KeyboardInterrupt                         Traceback (most recent call last)

    <ipython-input-89-0f31b4c5866a> in <module>
          3 
          4 # validation_split ã§æœ€å¾Œã®10ï¼…ã‚’æ¤œè¨¼ç”¨ã«åˆ©ç”¨ã—ã¾ã™
    ----> 5 history = model.fit(l_x, l_y, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=0)
    

    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
        817         max_queue_size=max_queue_size,
        818         workers=workers,
    --> 819         use_multiprocessing=use_multiprocessing)
        820 
        821   def evaluate(self,


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
        340                 mode=ModeKeys.TRAIN,
        341                 training_context=training_context,
    --> 342                 total_epochs=epochs)
        343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
        344 


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
        126         step=step, mode=mode, size=current_batch_size) as batch_logs:
        127       try:
    --> 128         batch_outs = execution_function(iterator)
        129       except (StopIteration, errors.OutOfRangeError):
        130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
         96     # `numpy` translates Tensors to values in Eager mode.
         97     return nest.map_structure(_non_none_constant_value,
    ---> 98                               distributed_function(input_fn))
         99 
        100   return execution_function


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
        566         xla_context.Exit()
        567     else:
    --> 568       result = self._call(*args, **kwds)
        569 
        570     if tracing_count == self._get_tracing_count():


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
        597       # In this case we have created variables on the first call, so we run the
        598       # defunned version which is guaranteed to never create variables.
    --> 599       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
        600     elif self._stateful_fn is not None:
        601       # Release the lock early so that multiple threads can perform the call


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
       2361     with self._lock:
       2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    -> 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
       2364 
       2365   @property


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)
       1609          if isinstance(t, (ops.Tensor,
       1610                            resource_variable_ops.BaseResourceVariable))),
    -> 1611         self.captured_inputs)
       1612 
       1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
       1690       # No tape is watching; skip to running the function.
       1691       return self._build_call_outputs(self._inference_function.call(
    -> 1692           ctx, args, cancellation_manager=cancellation_manager))
       1693     forward_backward = self._select_forward_and_backward_functions(
       1694         args,


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
        543               inputs=args,
        544               attrs=("executor_type", executor_type, "config_proto", config),
    --> 545               ctx=ctx)
        546         else:
        547           outputs = execute.execute_with_cancellation(


    ~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
         59     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,
         60                                                op_name, inputs, attrs,
    ---> 61                                                num_outputs)
         62   except core._NotOkStatusException as e:
         63     if name is not None:


    KeyboardInterrupt: 


## æå¤±é–¢æ•°ã®å¯è¦–åŒ–

å­¦ç¿’ã«ã‚ˆã£ã¦èª¤å·®ãŒæ¸›å°‘ã—ã¦ã„ãæ§˜å­ã‚’å¯è¦–åŒ–ã—ã¦ã¿ã¾ã™ã€‚


```python
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.plot(np.arange(len(loss)), loss, label='loss')
plt.plot(np.arange(len(val_loss)), val_loss, label='val_loss')
plt.grid()
plt.legend()
plt.show()
```

## çµæœã®ç¢ºèª


```python
# åˆæœŸã®å…¥åŠ›å€¤
res = l_y[0].reshape(-1)

for i in range(0, n):
  _y = model.predict(res[- NUM_LSTM:].reshape(1, NUM_LSTM, 1))
  res = np.append(res, _y[0][NUM_LSTM - 1][0])
  
plt.plot(np.arange(len(y)), y, label="nikkei stock")
plt.plot(np.arange(len(res)), res, label="lstm pred result")
plt.legend()
plt.grid()
plt.show()
```


```python

```


```python

```


```python

```


```python

```


```python

```


```python

```


```python



import os
import time
import warnings
import numpy as np
from numpy import newaxis
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM
from keras.models import Sequential

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.filterwarnings("ignore")

def load_data(filename, seq_len, normalise_window):
    f = open(filename, 'rb').read()
    data = f.decode().split('\n')

    sequence_length = seq_len + 1
    result = []
    for index in range(len(data) - sequence_length):
        result.append(data[index: index + sequence_length])

    if normalise_window:
        result = normalise_windows(result)

    result = np.array(result)

    row = round(0.9 * result.shape[0])
    train = result[:int(row),:]
    np.random.shuffle(train)
    x_train = train[:,:-1]
    y_train = train[:,-1]
    x_test = result[int(row):, :-1]
    y_test = result[int(row):, -1]

    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

    return [x_train, y_train, x_test, y_test]

def normalise_windows(window_data):
    normalised_data = []
    for window in window_data:
        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]
        normalised_data.append(normalised_window)
    return normalised_data

def build_model(layers):
    model = Sequential()

    model.add(LSTM(input_shape = (layers[1], layers[0]),
                    output_dim=layers[1],
                    return_sequences=True))
    model.add(Dropout(0.2))

    model.add(LSTM(layers[2],return_sequences=False))
    model.add(Dropout(0.2))

    model.add(Dense(output_dim=layers[3]))
    model.add(Activation("linear"))

    start = time.time()
    model.compile(loss="mse", optimizer='rmsprop')
    print(" å®Ÿè¡Œæ™‚é–“ï¼šã€€", time.time() - start)
    return model

def predict_point_by_point(model, data):
    predicted = model.predict(data)
    predicted = np.reshape(predicted, (predicted.size,))
    return predicted

def predict_sequence_full(model, data, window_size):
    curr_frame = data[0]
    predicted = []
    for i in range(len(data)):
        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])
        curr_frame = curr_frame[1:]
        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)
    return predicted

def predict_sequences_multiple(model, data, window_size, prediction_len):
    prediction_seqs = []
    for i in range(int(len(data)/prediction_len)):
        curr_frame = data[i*prediction_len]
        predicted = []
        for j in range(prediction_len):
            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])
            curr_frame = curr_frame[1:]
            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)
        prediction_seqs.append(predicted)
    return prediction_seqs

 import os
import time
import warnings
import numpy as np
from numpy import newaxis
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM
from keras.models import Sequential

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.filterwarnings("ignore")

def load_data(filename, seq_len, normalise_window):
    f = open(filename, 'rb').read()
    data = f.decode().split('\n')

    sequence_length = seq_len + 1
    result = []
    for index in range(len(data) - sequence_length):
        result.append(data[index: index + sequence_length])

    if normalise_window:
        result = normalise_windows(result)

    result = np.array(result)

    row = round(0.9 * result.shape[0])
    train = result[:int(row),:]
    np.random.shuffle(train)
    x_train = train[:,:-1]
    y_train = train[:,-1]
    x_test = result[int(row):, :-1]
    y_test = result[int(row):, -1]

    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

    return [x_train, y_train, x_test, y_test]

def normalise_windows(window_data):
    normalised_data = []
    for window in window_data:
        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]
        normalised_data.append(normalised_window)
    return normalised_data

def build_model(layers):
    model = Sequential()

    model.add(LSTM(input_shape = (layers[1], layers[0]),
                    output_dim=layers[1],
                    return_sequences=True))
    model.add(Dropout(0.2))

    model.add(LSTM(layers[2],return_sequences=False))
    model.add(Dropout(0.2))

    model.add(Dense(output_dim=layers[3]))
    model.add(Activation("linear"))

    start = time.time()
    model.compile(loss="mse", optimizer='rmsprop')
    print(" å®Ÿè¡Œæ™‚é–“ï¼šã€€", time.time() - start)
    return model

def predict_point_by_point(model, data):
    predicted = model.predict(data)
    predicted = np.reshape(predicted, (predicted.size,))
    return predicted

def predict_sequence_full(model, data, window_size):
    curr_frame = data[0]
    predicted = []
    for i in range(len(data)):
        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])
        curr_frame = curr_frame[1:]
        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)
    return predicted

def predict_sequences_multiple(model, data, window_size, prediction_len):
    prediction_seqs = []
    for i in range(int(len(data)/prediction_len)):
        curr_frame = data[i*prediction_len]
        predicted = []
        for j in range(prediction_len):
            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])
            curr_frame = curr_frame[1:]
            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)
        prediction_seqs.append(predicted)
    return prediction_seqs
 
"""
model.fit(X_train, y_train, batch_size=512, nb_epoch=epoch, validation_split=0.05)
predictions = lstm.predict_sequences_multiple(model, X_test, seq_len, 50)
model = lstm.build_model([1, 50, 100, 1])
"""

```


      File "<tokenize>", line 95
        import os
        ^
    IndentationError: unindent does not match any outer indentation level


