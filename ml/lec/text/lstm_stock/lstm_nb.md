
## kerasã¨LSTMã®åŸºç¤, RNNã¨ã®æ¯”è¼ƒ

ä»¥å‰ã®è¨˜äº‹ã§RNNã®å¾©ç¿’ã—ã¾ã—ãŸã®ã§ã€ã¤ã„ã§ã«LSTMã®å¾©ç¿’ã‚‚è¡Œã„ã¾ã™ã€‚LSTMã¯ Long Short Term Memory ã®ç•¥ã§ã€é•·æœŸçš„ãªä¾å­˜é–¢ä¿‚ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã®ã§ãã‚‹ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€RNNã®ä¸€ç¨®ã§ã€åŸºæœ¬çš„ãªè€ƒãˆæ–¹ã¯åŒã˜ã§ã™ã€‚è©³ç´°ã¯æ¤œç´¢ã™ã‚Œã°ã„ãã‚‰ã§ã‚‚å‡ºã¦ãã‚‹ã®ã§å‰²æ„›ã—ã¾ã™ã€‚

ã¾ãŸã€LSTMã¨RNNã®æ¯”è¼ƒã‚’è¡Œã„ã¾ã™ã€‚

### github
- jupyter notebookå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯[ã“ã¡ã‚‰](https://github.com/hiroshi0530/wa-src/tree/master/ml/lec/text/lstm/lstm_nb.ipynb)

### google colaboratory
- google colaboratory ã§å®Ÿè¡Œã™ã‚‹å ´åˆã¯[ã“ã¡ã‚‰](https://colab.research.google.com/github/hiroshi0530/wa-src/tree/master/ml/lec/text/lstm/lstm_nb.ipynb)

### ç­†è€…ã®ç’°å¢ƒ
ç­†è€…ã®OSã¯macOSã§ã™ã€‚Linuxã‚„Unixã®ã‚³ãƒãƒ³ãƒ‰ã¨ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒç•°ãªã‚Šã¾ã™ã€‚


```python
!sw_vers
```

    ProductName:	Mac OS X
    ProductVersion:	10.14.6
    BuildVersion:	18G6020



```python
!python -V
```

    Python 3.7.3


åŸºæœ¬çš„ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨kerasã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã—ã¦ãŠãã¾ã™ã€‚


```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

import matplotlib
import matplotlib.pyplot as plt
import scipy
import numpy as np
import pandas as pd

import tensorflow as tf
from tensorflow import keras

print('matplotlib version :', matplotlib.__version__)
print('scipy version :', scipy.__version__)
print('numpy version :', np.__version__)
print('tensorflow version : ', tf.__version__)
print('keras version : ', keras.__version__)
```

    matplotlib version : 3.0.3
    scipy version : 1.4.1
    numpy version : 1.19.4
    tensorflow version :  2.1.0
    keras version :  2.2.4-tf



```python

```


```python

```

## ãƒ‡ãƒ¼ã‚¿ã®å–å¾—

ä»Šå›ã¯æ—¥çµŒå¹³å‡ã¨ã‚¢ãƒ¡ãƒªã‚«ã®S&P500ã®æ ªä¾¡ã®ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ãã‚Œãã‚Œä»¥ä¸‹ã®ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚

### æ—¥çµŒå¹³å‡ã®ãƒ‡ãƒ¼ã‚¿

- https://indexes.nikkei.co.jp/nkave/index?type=download

### SP500ã®ãƒ‡ãƒ¼ã‚¿

- https://kabuoji3.com/stock/download.php


## ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
ã¾ãšæœ€åˆã«æ—¥çµŒã®ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¦ã¿ã¾ã™ã€‚


```python
!ls 
```

    lstm_nb.ipynb  lstm_nb.md     lstm_nb.py     [34mlstm_nb_files[m[m  nikkei.csv     sp500_2019.csv sp500_2020.csv



```bash
%%bash
head nikkei.csv
```

    ï¿½fï¿½[ï¿½^ï¿½ï¿½ï¿½t,ï¿½Iï¿½l,ï¿½nï¿½l,ï¿½ï¿½ï¿½l,ï¿½ï¿½ï¿½l
    "2017/01/04","19594.16","19298.68","19594.16","19277.93"
    "2017/01/05","19520.69","19602.10","19615.40","19473.28"
    "2017/01/06","19454.33","19393.55","19472.37","19354.44"
    "2017/01/10","19301.44","19414.83","19484.90","19255.35"
    "2017/01/11","19364.67","19358.64","19402.17","19325.46"
    "2017/01/12","19134.70","19300.19","19300.19","19069.02"
    "2017/01/13","19287.28","19174.97","19299.36","19156.93"
    "2017/01/16","19095.24","19219.13","19255.41","19061.27"
    "2017/01/17","18813.53","19038.45","19043.91","18812.86"


æ–‡å­—ã‚³ãƒ¼ãƒ‰ãŒshift-jisã«ãªã£ã¦ã„ã‚‹ã®ã§ã€utf-8ã«ç›´ã—ã¾ã™ã€‚


```bash
%%bash
nkf --guess nikkei.csv
```

    Shift_JIS (CRLF)



```bash
%%bash
nkf -w nikkei.csv > nikkei_utf8.csv
```


```bash
%%bash
head nikkei_utf8.csv
```

    ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜,çµ‚å€¤,å§‹å€¤,é«˜å€¤,å®‰å€¤
    "2017/01/04","19594.16","19298.68","19594.16","19277.93"
    "2017/01/05","19520.69","19602.10","19615.40","19473.28"
    "2017/01/06","19454.33","19393.55","19472.37","19354.44"
    "2017/01/10","19301.44","19414.83","19484.90","19255.35"
    "2017/01/11","19364.67","19358.64","19402.17","19325.46"
    "2017/01/12","19134.70","19300.19","19300.19","19069.02"
    "2017/01/13","19287.28","19174.97","19299.36","19156.93"
    "2017/01/16","19095.24","19219.13","19255.41","19061.27"
    "2017/01/17","18813.53","19038.45","19043.91","18812.86"


å•é¡Œãªã„ã‚ˆã†ãªã®ã§ã€pandasã§èª­ã¿è¾¼ã¿ã¾ã™ã€‚


```python
df = pd.read_csv('nikkei_utf8.csv')
```


```python
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜</th>
      <th>çµ‚å€¤</th>
      <th>å§‹å€¤</th>
      <th>é«˜å€¤</th>
      <th>å®‰å€¤</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2017/01/04</td>
      <td>19594.16</td>
      <td>19298.68</td>
      <td>19594.16</td>
      <td>19277.93</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2017/01/05</td>
      <td>19520.69</td>
      <td>19602.10</td>
      <td>19615.40</td>
      <td>19473.28</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2017/01/06</td>
      <td>19454.33</td>
      <td>19393.55</td>
      <td>19472.37</td>
      <td>19354.44</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2017/01/10</td>
      <td>19301.44</td>
      <td>19414.83</td>
      <td>19484.90</td>
      <td>19255.35</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2017/01/11</td>
      <td>19364.67</td>
      <td>19358.64</td>
      <td>19402.17</td>
      <td>19325.46</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.tail()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜</th>
      <th>çµ‚å€¤</th>
      <th>å§‹å€¤</th>
      <th>é«˜å€¤</th>
      <th>å®‰å€¤</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>971</th>
      <td>2020/12/24</td>
      <td>26668.35</td>
      <td>26635.11</td>
      <td>26764.53</td>
      <td>26605.26</td>
    </tr>
    <tr>
      <th>972</th>
      <td>2020/12/25</td>
      <td>26656.61</td>
      <td>26708.10</td>
      <td>26716.61</td>
      <td>26638.28</td>
    </tr>
    <tr>
      <th>973</th>
      <td>2020/12/28</td>
      <td>26854.03</td>
      <td>26691.29</td>
      <td>26854.03</td>
      <td>26664.60</td>
    </tr>
    <tr>
      <th>974</th>
      <td>2020/12/29</td>
      <td>27568.15</td>
      <td>26936.38</td>
      <td>27602.52</td>
      <td>26921.14</td>
    </tr>
    <tr>
      <th>975</th>
      <td>æœ¬è³‡æ–™ã¯æ—¥çµŒã®è‘—ä½œç‰©ã§ã‚ã‚Šã€æœ¬è³‡æ–™ã®å…¨éƒ¨åˆã¯ä¸€éƒ¨ã‚’ã€ã„ã‹ãªã‚‹å½¢å¼ã«ã‚ˆã£ã¦ã‚‚æ—¥çµŒã«ç„¡æ–­ã§è¤‡å†™ã€...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



æœ€å¾Œã®è¡Œã«è‘—ä½œæ¨©ã«é–¢ã™ã‚‹æ³¨æ„æ›¸ããŒã‚ã‚Šã¾ã™ãŒã€ã“ã‚Œã‚’å‰Šé™¤ã—ã¾ã™ã€‚è¤‡å†™ã‚„æµå¸ƒã¯è¡Œã„ã¾ã›ã‚“ã€‚


```python
df.drop(index=975, inplace=True)
```


```python
df.tail()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜</th>
      <th>çµ‚å€¤</th>
      <th>å§‹å€¤</th>
      <th>é«˜å€¤</th>
      <th>å®‰å€¤</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>970</th>
      <td>2020/12/23</td>
      <td>26524.79</td>
      <td>26580.43</td>
      <td>26585.21</td>
      <td>26414.74</td>
    </tr>
    <tr>
      <th>971</th>
      <td>2020/12/24</td>
      <td>26668.35</td>
      <td>26635.11</td>
      <td>26764.53</td>
      <td>26605.26</td>
    </tr>
    <tr>
      <th>972</th>
      <td>2020/12/25</td>
      <td>26656.61</td>
      <td>26708.10</td>
      <td>26716.61</td>
      <td>26638.28</td>
    </tr>
    <tr>
      <th>973</th>
      <td>2020/12/28</td>
      <td>26854.03</td>
      <td>26691.29</td>
      <td>26854.03</td>
      <td>26664.60</td>
    </tr>
    <tr>
      <th>974</th>
      <td>2020/12/29</td>
      <td>27568.15</td>
      <td>26936.38</td>
      <td>27602.52</td>
      <td>26921.14</td>
    </tr>
  </tbody>
</table>
</div>



ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã—ã¦ã¿ã¾ã™ã€‚ã‚³ãƒ­ãƒŠã‚·ãƒ§ãƒƒã‚¯ã§å¤§ããã¸ã“ã‚“ã§ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ãŒã€2020å¹´ã®å¹´æœ«ã®æ™‚ç‚¹ã§ã¯é‡‘èç·©å’Œã®å½±éŸ¿ã‚’å—ã‘ã¦å¤§å¹…ã«ä¸ŠãŒã£ã¦ã„ã¾ã™ã€‚


```python
ticks = 10
xticks = ticks * 5 

plt.plot(df['ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜'][::ticks], df['çµ‚å€¤'][::ticks], label='nikkei stock')
plt.grid()
plt.legend()
plt.xticks(df['ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜'][::xticks], rotation=60)
plt.show()
```


![svg](lstm_nb_files/lstm_nb_22_0.svg)



```python

```


```python



import os
import time
import warnings
import numpy as np
from numpy import newaxis
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM
from keras.models import Sequential

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.filterwarnings("ignore")

def load_data(filename, seq_len, normalise_window):
    f = open(filename, 'rb').read()
    data = f.decode().split('\n')

    sequence_length = seq_len + 1
    result = []
    for index in range(len(data) - sequence_length):
        result.append(data[index: index + sequence_length])

    if normalise_window:
        result = normalise_windows(result)

    result = np.array(result)

    row = round(0.9 * result.shape[0])
    train = result[:int(row),:]
    np.random.shuffle(train)
    x_train = train[:,:-1]
    y_train = train[:,-1]
    x_test = result[int(row):, :-1]
    y_test = result[int(row):, -1]

    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

    return [x_train, y_train, x_test, y_test]

def normalise_windows(window_data):
    normalised_data = []
    for window in window_data:
        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]
        normalised_data.append(normalised_window)
    return normalised_data

def build_model(layers):
    model = Sequential()

    model.add(LSTM(input_shape = (layers[1], layers[0]),
                    output_dim=layers[1],
                    return_sequences=True))
    model.add(Dropout(0.2))

    model.add(LSTM(layers[2],return_sequences=False))
    model.add(Dropout(0.2))

    model.add(Dense(output_dim=layers[3]))
    model.add(Activation("linear"))

    start = time.time()
    model.compile(loss="mse", optimizer='rmsprop')
    print(" å®Ÿè¡Œæ™‚é–“ï¼šã€€", time.time() - start)
    return model

def predict_point_by_point(model, data):
    predicted = model.predict(data)
    predicted = np.reshape(predicted, (predicted.size,))
    return predicted

def predict_sequence_full(model, data, window_size):
    curr_frame = data[0]
    predicted = []
    for i in range(len(data)):
        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])
        curr_frame = curr_frame[1:]
        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)
    return predicted

def predict_sequences_multiple(model, data, window_size, prediction_len):
    prediction_seqs = []
    for i in range(int(len(data)/prediction_len)):
        curr_frame = data[i*prediction_len]
        predicted = []
        for j in range(prediction_len):
            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])
            curr_frame = curr_frame[1:]
            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)
        prediction_seqs.append(predicted)
    return prediction_seqs

 import os
import time
import warnings
import numpy as np
from numpy import newaxis
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM
from keras.models import Sequential

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.filterwarnings("ignore")

def load_data(filename, seq_len, normalise_window):
    f = open(filename, 'rb').read()
    data = f.decode().split('\n')

    sequence_length = seq_len + 1
    result = []
    for index in range(len(data) - sequence_length):
        result.append(data[index: index + sequence_length])

    if normalise_window:
        result = normalise_windows(result)

    result = np.array(result)

    row = round(0.9 * result.shape[0])
    train = result[:int(row),:]
    np.random.shuffle(train)
    x_train = train[:,:-1]
    y_train = train[:,-1]
    x_test = result[int(row):, :-1]
    y_test = result[int(row):, -1]

    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

    return [x_train, y_train, x_test, y_test]

def normalise_windows(window_data):
    normalised_data = []
    for window in window_data:
        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]
        normalised_data.append(normalised_window)
    return normalised_data

def build_model(layers):
    model = Sequential()

    model.add(LSTM(input_shape = (layers[1], layers[0]),
                    output_dim=layers[1],
                    return_sequences=True))
    model.add(Dropout(0.2))

    model.add(LSTM(layers[2],return_sequences=False))
    model.add(Dropout(0.2))

    model.add(Dense(output_dim=layers[3]))
    model.add(Activation("linear"))

    start = time.time()
    model.compile(loss="mse", optimizer='rmsprop')
    print(" å®Ÿè¡Œæ™‚é–“ï¼šã€€", time.time() - start)
    return model

def predict_point_by_point(model, data):
    predicted = model.predict(data)
    predicted = np.reshape(predicted, (predicted.size,))
    return predicted

def predict_sequence_full(model, data, window_size):
    curr_frame = data[0]
    predicted = []
    for i in range(len(data)):
        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])
        curr_frame = curr_frame[1:]
        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)
    return predicted

def predict_sequences_multiple(model, data, window_size, prediction_len):
    prediction_seqs = []
    for i in range(int(len(data)/prediction_len)):
        curr_frame = data[i*prediction_len]
        predicted = []
        for j in range(prediction_len):
            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])
            curr_frame = curr_frame[1:]
            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)
        prediction_seqs.append(predicted)
    return prediction_seqs
 

"model.fit(X_train, y_train, batch_size=512, nb_epoch=epoch, validation_split=0.05)"
 "predictions = lstm.predict_sequences_multiple(model, X_test, seq_len, 50)"


```


```python

```


```python

```


```python

```


```python

```


```python

```


```python

```


```python

```


```python

```

## æ¸›è¡°æŒ¯å‹•æ›²ç·š

ã‚µãƒ³ãƒ—ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã€ä»¥ä¸‹ã®å¼ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚

$$
y = \exp\left(-\frac{x}{\tau}\right)\cos(x) 
$$

æ³¢ã‚’æ‰“ã¡ãªãŒã‚‰ã€æ¬¡ç¬¬ã«åæŸã—ã¦ã„ãã€è‡ªç„¶ç¾è±¡ã§ã¯ã‚ˆãã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã«ãªã‚Šã¾ã™ã€‚å˜ç´”ãªRNNã¨æ¯”è¼ƒã™ã‚‹ãŸã‚ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯åŒã˜é–¢æ•°ã¨ã—ã¾ã™ã€‚


```python
x = np.linspace(0, 5 * np.pi, 200)
y = np.exp(-x / 5) * (np.cos(x))
```

### ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª

$x$ã¨$y$ã®ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¦‹ã¦ã¿ã¾ã™ã€‚


```python
print('shape : ', x.shape)
print('ndim : ', x.ndim)
print('data : ', x[:10])
```

    shape :  (200,)
    ndim :  1
    data :  [0.         0.07893449 0.15786898 0.23680347 0.31573796 0.39467244
     0.47360693 0.55254142 0.63147591 0.7104104 ]



```python
print('shape : ', y.shape)
print('ndim : ', y.ndim)
print('data : ', y[:10])
```

    shape :  (200,)
    ndim :  1
    data :  [1.         0.98127212 0.9568705  0.92712705 0.89239742 0.85305798
     0.80950282 0.76214062 0.71139167 0.65768474]


ã‚°ãƒ©ãƒ•ã‚’ç¢ºèªã—ã¦ã¿ã¾ã™ã€‚


```python
plt.plot(x,y)
plt.grid()
plt.show()
```


![svg](lstm_nb_files/lstm_nb_39_0.svg)


$\tau=5$ã¨ã—ã¦ã€ç¶ºéº—ãªæ¸›è¡°æ›²ç·šãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚

## ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®æ§‹ç¯‰

kerasã«æŠ•å…¥ã™ã‚‹ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’è¡Œã„ã€å†å¸°å‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®æ§‹ç¯‰ã‚’è¡Œã„ã¾ã™ã€‚

æ§‹ç¯‰ãŒçµ‚äº†ã—ãŸã‚‰ã€compileãƒ¡ã‚½ãƒƒãƒ‰ã‚’åˆ©ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¾ã™ã€‚compileã®ä»•æ§˜ã¯ä»¥ä¸‹ã®æ§˜ã«ãªã£ã¦ã„ã¾ã™ã€‚

```bash
compile(self, optimizer, loss, metrics=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)
```


```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM

NUM_RNN = 20
NUM_MIDDLE = 40

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
n = len(x) - NUM_RNN
r_x = np.zeros((n, NUM_RNN))
r_y = np.zeros((n, NUM_RNN))
for i in range(0, n):
  r_x[i] = y[i: i + NUM_RNN]
  r_y[i] = y[i + 1: i + NUM_RNN + 1]

r_x = r_x.reshape(n, NUM_RNN, 1)
r_y = r_y.reshape(n, NUM_RNN, 1)

# RNNãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®æ§‹ç¯‰
rnn_model = Sequential()
rnn_model.add(SimpleRNN(NUM_MIDDLE, input_shape=(NUM_RNN, 1), return_sequences=True))
rnn_model.add(Dense(1, activation="linear"))
rnn_model.compile(loss="mean_squared_error", optimizer="sgd")

# LSTMãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®æ§‹ç¯‰
lstm_model = Sequential()
lstm_model.add(LSTM(NUM_MIDDLE, input_shape=(NUM_RNN, 1), return_sequences=True))
lstm_model.add(Dense(1, activation="linear"))
lstm_model.compile(loss="mean_squared_error", optimizer="sgd")
```

æŠ•å…¥ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„ã€ãƒ¢ãƒ‡ãƒ«ã®æ¦‚è¦ã‚’ç¢ºèªã—ã¾ã™ã€‚


```python
print(r_y.shape)
print(r_x.shape)
```

    (180, 20, 1)
    (180, 20, 1)


äºŒã¤ã®ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã‚’è¡Œã„ã¾ã™ã€‚LSTMã®æ–¹ãŒãƒ‘ãƒ©ãƒ¡ã‚¿æ•°ãŒå¤šã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚å­¦ç¿’ã™ã‚‹ã«ã‚‚LSTMã®æ–¹ãŒæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚


```python
print(rnn_model.summary())
print(lstm_model.summary())
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    simple_rnn (SimpleRNN)       (None, 20, 40)            1680      
    _________________________________________________________________
    dense (Dense)                (None, 20, 1)             41        
    =================================================================
    Total params: 1,721
    Trainable params: 1,721
    Non-trainable params: 0
    _________________________________________________________________
    None
    Model: "sequential_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    lstm (LSTM)                  (None, 20, 40)            6720      
    _________________________________________________________________
    dense_1 (Dense)              (None, 20, 1)             41        
    =================================================================
    Total params: 6,761
    Trainable params: 6,761
    Non-trainable params: 0
    _________________________________________________________________
    None


## å­¦ç¿’

fitãƒ¡ã‚½ãƒƒãƒ‰ã‚’åˆ©ç”¨ã—ã¦ã€å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚
fitãƒ¡ã‚½ãƒƒãƒ‰ã®ä»•æ§˜ã¯ä»¥ä¸‹ã®é€šã‚Šã«ãªã£ã¦ã„ã¾ã™ã€‚[ã“ã¡ã‚‰](https://keras.io/ja/models/sequential/)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

```bash
fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)
```


```python
batch_size = 10
epochs = 1000

# validation_split ã§æœ€å¾Œã®10ï¼…ã‚’æ¤œè¨¼ç”¨ã«åˆ©ç”¨ã—ã¾ã™
rnn_history = rnn_model.fit(r_x, r_y, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=0)

# validation_split ã§æœ€å¾Œã®10ï¼…ã‚’æ¤œè¨¼ç”¨ã«åˆ©ç”¨ã—ã¾ã™
lstm_history = lstm_model.fit(r_x, r_y, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=0)
```

## æå¤±é–¢æ•°ã®å¯è¦–åŒ–

å­¦ç¿’ã«ã‚ˆã£ã¦èª¤å·®ãŒæ¸›å°‘ã—ã¦ã„ãæ§˜å­ã‚’å¯è¦–åŒ–ã—ã¦ã¿ã¾ã™ã€‚


```python
rnn_loss = rnn_history.history['loss'] # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æå¤±é–¢æ•°
rnn_val_loss = rnn_history.history['val_loss'] #ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æå¤±é–¢æ•°

lstm_loss = lstm_history.history['loss'] # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æå¤±é–¢æ•°
lstm_val_loss = lstm_history.history['val_loss'] #ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æå¤±é–¢æ•°

plt.plot(np.arange(len(rnn_loss)), rnn_loss, label='rnn_loss')
plt.plot(np.arange(len(rnn_val_loss)), rnn_val_loss, label='rnn_val_loss')
plt.plot(np.arange(len(lstm_loss)), lstm_loss, label='lstm_loss')
plt.plot(np.arange(len(lstm_val_loss)), lstm_val_loss, label='lstm_val_loss')
plt.grid()
plt.legend()
plt.show()
```


![svg](lstm_nb_files/lstm_nb_50_0.svg)


## çµæœã®ç¢ºèª


```python
# åˆæœŸã®å…¥åŠ›å€¤
rnn_res = r_y[0].reshape(-1)
lstm_res = r_y[0].reshape(-1)

for i in range(0, n):
  _rnn_y = rnn_model.predict(rnn_res[- NUM_RNN:].reshape(1, NUM_RNN, 1))
  rnn_res = np.append(rnn_res, _rnn_y[0][NUM_RNN - 1][0])
  
  _lstm_y = lstm_model.predict(lstm_res[- NUM_RNN:].reshape(1, NUM_RNN, 1))
  lstm_res = np.append(lstm_res, _lstm_y[0][NUM_RNN - 1][0])
  
plt.plot(np.arange(len(y)), y, label=r"$\exp\left(-\frac{x}{\tau}\right) \cos x$")
plt.plot(np.arange(len(rnn_res)), rnn_res, label="RNN result")
plt.plot(np.arange(len(lstm_res)), lstm_res, label="LSTM result")
plt.legend()
plt.grid()
plt.show()
```


![svg](lstm_nb_files/lstm_nb_52_0.svg)


æ¸›è¡°æŒ¯å‹•æ›²ç·šã®å ´åˆã€ä»Šå›è¨­å®šã—ãŸãƒ‘ãƒ©ãƒ¡ã‚¿ã§ã¯ã€LSTMã¨RNNã®å·®ã¯å‡ºã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚ãŸã ã€å®Ÿå‹™ãƒ¬ãƒ™ãƒ«ã§ã¯ã€RNNã‚ˆã‚ŠLSTMã®æ–¹ãŒã‚ˆã‚Šä½¿ã‚ã‚Œã¦ãŠã‚Šã€çµæœã‚‚å‡ºã¦ã„ã‚‹ã‚ˆã†ã«æ€ã„ã¾ã™ã€‚ä»Šå›ã¯ãŸã ã®ç·´ç¿’ãªã®ã§ã€ã“ã“ã§çµ‚ã‚ã‚Šã«ã—ã‚ˆã†ã¨æ€ã„ã¾ã™ã€‚
