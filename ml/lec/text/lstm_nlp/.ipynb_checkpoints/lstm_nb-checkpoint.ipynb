{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kerasとLSTMを用いた文章の生成\n",
    "\n",
    "LSTMを用いて文章を生成することが出来ます。文章を時系列データとして訓練データとして学習し、文章を入力し、次の文字列を予測するようなっモデルを生成します。今回は前回青空文庫からダウンロードした、宮沢賢治の銀河鉄道の夜を学習データとして採用し、LSTMによって、宮沢賢治風の文章を作成してみようと思います。\n",
    "\n",
    "### github\n",
    "- jupyter notebook形式のファイルは[こちら](https://github.com/hiroshi0530/wa-src/tree/master/ml/lec/text/lstm_nlp/lstm_nb.ipynb)\n",
    "\n",
    "### google colaboratory\n",
    "- google colaboratory で実行する場合は[こちら](https://colab.research.google.com/github/hiroshi0530/wa-src/tree/master/ml/lec/text/lstm_nlp/lstm_nb.ipynb)\n",
    "\n",
    "### 筆者の環境\n",
    "筆者のOSはmacOSです。LinuxやUnixのコマンドとはオプションが異なります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductName:\tMac OS X\r\n",
      "ProductVersion:\t10.14.6\r\n",
      "BuildVersion:\t18G6020\r\n"
     ]
    }
   ],
   "source": [
    "!sw_vers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的なライブラリとkerasをインポートしそのバージョンを確認しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version : 3.0.3\n",
      "scipy version : 1.4.1\n",
      "numpy version : 1.19.4\n",
      "tensorflow version :  2.4.0\n",
      "keras version :  2.4.0\n",
      "gensim version :  3.8.3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gensim\n",
    "import gensim\n",
    "\n",
    "print('matplotlib version :', matplotlib.__version__)\n",
    "print('scipy version :', scipy.__version__)\n",
    "print('numpy version :', np.__version__)\n",
    "print('tensorflow version : ', tf.__version__)\n",
    "print('keras version : ', keras.__version__)\n",
    "print('gensim version : ', gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストファイルの前処理\n",
    "\n",
    "題材として、宮沢賢治の銀河鉄道の夜を利用します。既に著作権フリーなので、自由に利用できます。ちなみに、宮沢賢治は同郷で高校の先輩ですが、日本語が全く出来ない私は一度も読んだことはないです。ですので、LSTMによる文章が自然なものなのか、宮沢賢治風なのか、不明です。。\n",
    "\n",
    "銀河鉄道の夜は以前、word2vecを利用した[分散表現の作成の記事](/ml/lec/text/w2v/)で利用しました。\n",
    "テキストの前処理などは重複する部分があるかと思います。\n",
    "\n",
    "まずはテキストの中身を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "銀河鉄道の夜\n",
      "宮沢賢治\n",
      "\n",
      "-------------------------------------------------------\n",
      "【テキスト中に現れる記号について】\n",
      "\n",
      "《》：ルビ\n",
      "（例）北十字《きたじふじ》\n",
      "\n",
      "［＃］：入力者注　主に外字の説明や、傍点の位置の指定\n",
      "　　　（数字は、JIS X 0213の面区点番号またはUnicode、底本のページと行数）\n",
      "（例）※［＃小書き片仮名ヰ、155-15］\n",
      "\n",
      "　［＃（…）］：訓点送り仮名\n",
      "　（例）僕［＃（ん）］とこ\n",
      "-------------------------------------------------------\n",
      "\n",
      "［＃７字下げ］一、午后の授業［＃「一、午后の授業」は中見出し］\n",
      "\n",
      "「ではみなさんは、さういふふうに川だと云はれたり、乳の流れたあとだと云はれたりしてゐたこのぼんやりと白いものがほんたうは何かご承知ですか。」先生は、黒板に吊した大きな黒い星座の図の、上から下へ白くけぶった銀河帯のやうなところを指しながら、みんなに問をかけました。\n",
      "カムパネルラが手をあげました。それから四五人手をあげました。ジョバンニも手をあげやうとして、急いでそのまゝやめました。たしかにあれがみんな星だと、いつか雑誌で読んだのでしたが、このごろはジョバンニはまるで毎日教室でもねむく、本を読むひまも読む本もないので、なんだかどんなこともよくわからないといふ気持ちがするのでした。\n",
      "ところが先生は早くもそれを見附けたのでした。\n",
      "「ジョバンニさん。あなたはわかってゐるのでせう。」\n",
      "ジョバンニは勢よく立ちあがりましたが、立って見るともうはっきりとそれを答へることができないのでした。ザネリが前の席からふりかへって、ジョバンニを見てくすっとわらひました。ジョバンニはもうどぎまぎしてまっ赤になってしまひました。先生がまた云ひました。\n",
      "「大きな望遠鏡で銀河をよっく調べると銀河は大体何でせう。」\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat ginga.txt | head -n 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ジョバンニはそのカムパネルラはもうあの銀河のはづれにしかゐないといふやうな気がしてしかたなかったのです。\n",
      "けれどもみんなはまだ、どこかの波の間から、\n",
      "「ぼくずゐぶん泳いだぞ。」と云ひながらカムパネルラが出て来るか或ひはカムパネルラがどこかの人の知らない洲にでも着いて立ってゐて誰かの来るのを待ってゐるかといふやうな気がして仕方ないらしいのでした。けれども俄かにカムパネルラのお父さんがきっぱり云ひました。\n",
      "「もう駄目です。落ちてから四十五分たちましたから。」\n",
      "ジョバンニは思はずか〔け〕よって博士の前に立って、ぼくはカムパネルラの行った方を知ってゐますぼくはカムパネルラといっしょに歩いてゐたのですと云はうとしましたがもうのどがつまって何とも云へませんでした。すると博士はジョバンニが挨拶に来たとでも思ったものですか　しばらくしげしげジョバンニを見てゐましたが\n",
      "「あなたはジョバンニさんでしたね。どうも今晩はありがたう。」と叮ねいに云ひました。\n",
      "　ジョバンニは何も云へずにたゞおじぎをしました。\n",
      "「あなたのお父さんはもう帰ってゐますか。」博士は堅く時計を握ったまゝまたきゝました。\n",
      "「いゝえ。」ジョバンニはかすかに頭をふりました。\n",
      "「どうしたのかなあ、ぼくには一昨日大へん元気な便りがあったんだが。今日あ〔〕たりもう着くころなんだが。船が遅れたんだな。ジョバンニさん。あした放課后みなさんとうちへ遊びに来てくださいね。」\n",
      "さう云ひながら博士は〔〕また川下の銀河のいっぱいにうつった方へじっと眼を送りました。ジョバンニはもういろいろなことで胸がいっぱいでなんにも云へずに博士の前をはなれて早くお母さんに牛乳を持って行ってお父さんの帰ることを知らせやうと思ふともう一目散に河原を街の方へ走りました。\n",
      "\n",
      "\n",
      "\n",
      "底本：「【新】校本宮澤賢治全集　第十一巻　童話※［＃ローマ数字4、1-13-24］　本文篇」筑摩書房\n",
      "　　　1996（平成8）年1月25日初版第1刷発行\n",
      "※底本のテキストは、著者草稿によります。\n",
      "※底本では校訂及び編者による説明を「〔　〕」、削除を「〔〕」で表示しています。\n",
      "※「カムパネルラ」と「カンパネルラ」の混在は、底本通りです。\n",
      "※底本は新字旧仮名づかいです。なお拗音、促音の小書きは、底本通りです。\n",
      "入力：砂場清隆\n",
      "校正：北川松生\n",
      "2016年6月10日作成\n",
      "青空文庫作成ファイル：\n",
      "このファイルは、インターネットの図書館、青空文庫（http://www.aozora.gr.jp/）で作られました。入力、校正、制作にあたったのは、ボランティアの皆さんです。\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat ginga.txt | tail -n 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となり、ファイルの先頭と、末尾に参考情報が載っているほかは、ちゃんとテキストとしてデータが取れている模様です。\n",
    "先ず、この辺の前処理を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('ginga.txt', mode='r') as f:\n",
    "  all_sentence = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence = all_sentence.replace(\" \", \"\").replace(\"　\",\"\").replace(\"\\n\",\"\").replace(\"|\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《》で囲まれたルビの部分を削除します。正規表現を利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence = re.sub(\"《[^》]+》\", \"\", all_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------の部分で分割を行い、2番目の要素を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'［＃７字下げ］一、午后の授業［＃「一、午后の授業」は中見出し］「ではみなさんは、さういふふうに川だと云はれたり、乳の流れたあとだと云はれたりしてゐたこのぼんやりと白いものがほんたうは何かご承知ですか。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentence = re.split(\"\\-{8,}\", all_sentence)[2]\n",
    "all_sentence[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となり、不要な部分を削除し、必要な部分をall_sentenceに格納しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot vectorの作成\n",
    "\n",
    "文章を学習させるには、日本語の文字1文字1文字をベクトルとして表現する必要があります。前回やったとおりword2vecを用いてベクトル表現を得る方法もありますが、ここでは、それぞれの文字に対して、`[0,0,1,0,0]`などのone-hot-vectorを付与します。ですので、ベクトルの次元数としては、文字数分だけあり、学習にかなりの時間を要します。\n",
    "\n",
    "まず、銀河鉄道の夜で利用されている文字をすべて取り出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-', '.', '/', '0', '1', '2', '3', '4', '5', '6']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars = sorted(list(set(all_sentence)))\n",
    "all_chars[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、文字に対して数字を対応させます。上記の`all_chars`に格納された順番の数字を付与します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_num_dic = dict((c, i) for i, c in enumerate(all_chars))\n",
    "num_char_dic = dict((i, c) for i, c in enumerate(all_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "後の処理を簡単にするために、文字列を受け取って、対応する数字のリストを返す関数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scalar_list(char_list):\n",
    "  return [char_num_dic[c] for c in char_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この関数を利用し、予想に利用する文字列と予想する文字を数字のリストに変換します。\n",
    "\n",
    "また、LSTMで予測するのに必要な時系列データの数を100とします。\n",
    "100個の文字列から、次の1文字を予測するモデルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LSTM = 100\n",
    "\n",
    "train_chars_list = []\n",
    "predict_char_list = []\n",
    "for c in range(0, len(all_sentence) - NUM_LSTM):\n",
    "  train_chars_list.append(get_scalar_list(all_sentence[c: c + NUM_LSTM]))\n",
    "  predict_char_list.append(char_num_dic[all_sentence[c + NUM_LSTM]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1117, 1110, 1114, 403, 190, 50, 1118, 183, 26, 295, 327, 78, 538, 628, 1117, 1110, 29, 183, 26, 295, 327, 78, 538, 628, 30, 79, 195, 942, 261, 55, 1118, 29, 71, 79, 94, 74, 53, 112, 79, 26, 53, 39, 38, 85, 85, 39, 75, 440, 64, 72, 204, 79, 107, 63, 105, 26, 201, 78, 682, 107, 63, 36, 72, 64, 72, 204, 79, 107, 63, 105, 55, 70, 110, 63, 51, 78, 91, 112, 99, 105, 72, 769, 38, 97, 78, 44, 90, 112, 63, 39, 79, 225, 43, 52, 519, 790, 71, 57, 43, 27]\n"
     ]
    }
   ],
   "source": [
    "print(train_chars_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(predict_char_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_chars[0]からpredict_char[0]を予測するようなモデルを作成します。\n",
    "\n",
    "これらの数字をone hot vectorで表現します。\n",
    "\n",
    "表現するベクトルのサイズは`len(all_chars)`となります。また、kerasに投入することを前提に、入力するテンソルの形状として\n",
    "\n",
    "`(サンプル数、予測に利用する時系列データの数、one-hot-vectorの次元)`となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xを入力するデータ\n",
    "# yを正解データ\n",
    "# one-hot-vectorを入力するため、最初にゼロベクトルを作成します。\n",
    "\n",
    "x = np.zeros((len(train_chars_list), NUM_LSTM, len(all_chars)), dtype=np.bool)\n",
    "y = np.zeros((len(predict_char_list), len(all_chars)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要な部分だけ1に修正します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力データに割り当てられた数字の要素を1に設定します。\n",
    "for i in range(len(train_chars_list)):\n",
    "  for j in range(NUM_LSTM):\n",
    "    x[i, j, train_chars_list[i][j]] = 1\n",
    "\n",
    "# 正解データに割り当てられた数字の要素を1に設定します。\n",
    "for i in range(len(predict_char_list)):\n",
    "  y[i, predict_char_list[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot-vectorの確認\n",
    "\n",
    "実際に想定通りone-hot-vectorが出来ているか確認してみます。`np.where`を利用してtrueとなっているインデックスを取得してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1117, 1110, 1114,  403,  190,   50, 1118,  183,   26,  295,  327,\n",
       "         78,  538,  628, 1117, 1110,   29,  183,   26,  295,  327,   78,\n",
       "        538,  628,   30,   79,  195,  942,  261,   55, 1118,   29,   71,\n",
       "         79,   94,   74,   53,  112,   79,   26,   53,   39,   38,   85,\n",
       "         85,   39,   75,  440,   64,   72,  204,   79,  107,   63,  105,\n",
       "         26,  201,   78,  682,  107,   63,   36,   72,   64,   72,  204,\n",
       "         79,  107,   63,  105,   55,   70,  110,   63,   51,   78,   91,\n",
       "        112,   99,  105,   72,  769,   38,   97,   78,   44,   90,  112,\n",
       "         63,   39,   79,  225,   43,   52,  519,  790,   71,   57,   43])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(x[0][:-1] == 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y[0] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となり、想定通りone-hot-vectorが出来ていることがわかりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築\n",
    "\n",
    "LSTMのモデルを構築する関数を作成します。\n",
    "ここでは簡単にLSTMと全結合層で構成されたモデルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 300)               1704000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1119)              336819    \n",
      "=================================================================\n",
      "Total params: 2,040,819\n",
      "Trainable params: 2,040,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "NUM_MIDDLE = 300\n",
    "\n",
    "def build_lstm_model():\n",
    "  lstm_model = Sequential()\n",
    "  lstm_model.add(LSTM(NUM_MIDDLE, input_shape=(NUM_LSTM, len(all_chars))))\n",
    "  lstm_model.add(Dense(len(all_chars), activation=\"softmax\"))\n",
    "  lstm_model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "  \n",
    "  print(lstm_model.summary())\n",
    "  \n",
    "  return lstm_model\n",
    "\n",
    "model = build_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch終了後に実行させるコールバック関数を実行させます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    " \n",
    "def on_epoch_end(epoch, logs):\n",
    "  print(\"エポック: \", epoch)\n",
    "\n",
    "  beta = 5  # 確率分布を調整する定数\n",
    "  prev_text = text[0: NUM_LSTM]  # 入力に使う文字\n",
    "  created_text = prev_text  # 生成されるテキスト\n",
    "  \n",
    "  print(\"シード: \", created_text)\n",
    "\n",
    "  for i in range(400):\n",
    "    # 入力をone-hot表現に\n",
    "    x_pred = np.zeros((1, NUM_LSTM, len(all_chars)))\n",
    "    for j, char in enumerate(prev_text):\n",
    "      x_pred[0, j, char_indices[char]] = 1\n",
    "    \n",
    "    # 予測を行い、次の文字を得る\n",
    "    y = model.predict(x_pred)\n",
    "    p_power = y[0] ** beta  # 確率分布の調整\n",
    "    next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power))    \n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    created_text += next_char\n",
    "    prev_text = prev_text[1:] + next_char\n",
    "\n",
    "  print(created_text)\n",
    "\n",
    "# エポック終了後に実行される関数を設定\n",
    "epoch_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 34/391 [=>............................] - ETA: 15:11 - loss: 6.2912"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-837be0bb79ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_end_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## とても時間がかかる\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "history = model.fit(x, y, batch_size=batch_size, epochs=epochs, callbacks=[epoch_end_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# インデックスと文字で辞書を作成\n",
    "chars = sorted(list(set(text)))  # setで文字の重複をなくし、各文字をリストに格納する\n",
    "print(\"文字数（重複無し）\", len(chars))\n",
    "char_indices = {}  # 文字がキーでインデックスが値\n",
    "for i, char in enumerate(chars):\n",
    "  char_indices[char] = i\n",
    "indices_char = {}  # インデックスがキーで文字が値\n",
    "for i, char in enumerate(chars):\n",
    "  indices_char[i] = char\n",
    " \n",
    "# 時系列データと、それから予測すべき文字を取り出します\n",
    "time_chars = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - n_rnn):\n",
    "  time_chars.append(text[i: i + n_rnn])\n",
    "  next_chars.append(text[i + n_rnn])\n",
    " \n",
    "# 入力と正解をone-hot表現で表します\n",
    "x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)\n",
    "t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)\n",
    "for i, t_cs in enumerate(time_chars):\n",
    "  t[i, char_indices[next_chars[i]]] = 1  # 正解をone-hot表現で表す\n",
    "  for j, char in enumerate(t_cs):\n",
    "    x[i, j, char_indices[char]] = 1  # 入力をone-hot表現で表す\n",
    "    \n",
    "print(\"xの形状\", x.shape)\n",
    "print(\"tの形状\", t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 減衰振動曲線\n",
    "\n",
    "サンプル用のデータとして、以下の式からサンプリングを行います。\n",
    "\n",
    "$$\n",
    "y = \\exp\\left(-\\frac{x}{\\tau}\\right)\\cos(x) \n",
    "$$\n",
    "\n",
    "波を打ちながら、次第に収束していく、自然現象ではよくあるモデルになります。単純なRNNと比較するため、サンプルデータは同じ関数とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 5 * np.pi, 200)\n",
    "y = np.exp(-x / 5) * (np.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの確認\n",
    "\n",
    "$x$と$y$のデータの詳細を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape : ', x.shape)\n",
    "print('ndim : ', x.ndim)\n",
    "print('data : ', x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape : ', y.shape)\n",
    "print('ndim : ', y.ndim)\n",
    "print('data : ', y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフを確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tau=5$として、綺麗な減衰曲線が得られました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットの構築\n",
    "\n",
    "kerasに投入するためにデータの前処理を行い、再帰型のニューラルネットの構築を行います。\n",
    "\n",
    "構築が終了したら、compileメソッドを利用して、モデルをコンパイルします。compileの仕様は以下の様になっています。\n",
    "\n",
    "```bash\n",
    "compile(self, optimizer, loss, metrics=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "NUM_RNN = 20\n",
    "NUM_MIDDLE = 40\n",
    "\n",
    "# データの前処理\n",
    "n = len(x) - NUM_RNN\n",
    "r_x = np.zeros((n, NUM_RNN))\n",
    "r_y = np.zeros((n, NUM_RNN))\n",
    "for i in range(0, n):\n",
    "  r_x[i] = y[i: i + NUM_RNN]\n",
    "  r_y[i] = y[i + 1: i + NUM_RNN + 1]\n",
    "\n",
    "r_x = r_x.reshape(n, NUM_RNN, 1)\n",
    "r_y = r_y.reshape(n, NUM_RNN, 1)\n",
    "\n",
    "# RNNニューラルネットの構築\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(NUM_MIDDLE, input_shape=(NUM_RNN, 1), return_sequences=True))\n",
    "rnn_model.add(Dense(1, activation=\"linear\"))\n",
    "rnn_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "# LSTMニューラルネットの構築\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(NUM_MIDDLE, input_shape=(NUM_RNN, 1), return_sequences=True))\n",
    "lstm_model.add(Dense(1, activation=\"linear\"))\n",
    "lstm_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "投入するデータや、モデルの概要を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_y.shape)\n",
    "print(r_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二つのモデルの比較を行います。LSTMの方がパラメタ数が多いことがわかります。学習するにもLSTMの方が時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rnn_model.summary())\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "\n",
    "fitメソッドを利用して、学習を行います。\n",
    "fitメソッドの仕様は以下の通りになっています。[こちら](https://keras.io/ja/models/sequential/)を参照してください。\n",
    "\n",
    "```bash\n",
    "fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 1000\n",
    "\n",
    "# validation_split で最後の10％を検証用に利用します\n",
    "rnn_history = rnn_model.fit(r_x, r_y, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=0)\n",
    "\n",
    "# validation_split で最後の10％を検証用に利用します\n",
    "lstm_history = lstm_model.fit(r_x, r_y, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数の可視化\n",
    "\n",
    "学習によって誤差が減少していく様子を可視化してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_loss = rnn_history.history['loss'] # 訓練データの損失関数\n",
    "rnn_val_loss = rnn_history.history['val_loss'] #テストデータの損失関数\n",
    "\n",
    "lstm_loss = lstm_history.history['loss'] # 訓練データの損失関数\n",
    "lstm_val_loss = lstm_history.history['val_loss'] #テストデータの損失関数\n",
    "\n",
    "plt.plot(np.arange(len(rnn_loss)), rnn_loss, label='rnn_loss')\n",
    "plt.plot(np.arange(len(rnn_val_loss)), rnn_val_loss, label='rnn_val_loss')\n",
    "plt.plot(np.arange(len(lstm_loss)), lstm_loss, label='lstm_loss')\n",
    "plt.plot(np.arange(len(lstm_val_loss)), lstm_val_loss, label='lstm_val_loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期の入力値\n",
    "rnn_res = r_y[0].reshape(-1)\n",
    "lstm_res = r_y[0].reshape(-1)\n",
    "\n",
    "for i in range(0, n):\n",
    "  _rnn_y = rnn_model.predict(rnn_res[- NUM_RNN:].reshape(1, NUM_RNN, 1))\n",
    "  rnn_res = np.append(rnn_res, _rnn_y[0][NUM_RNN - 1][0])\n",
    "  \n",
    "  _lstm_y = lstm_model.predict(lstm_res[- NUM_RNN:].reshape(1, NUM_RNN, 1))\n",
    "  lstm_res = np.append(lstm_res, _lstm_y[0][NUM_RNN - 1][0])\n",
    "  \n",
    "plt.plot(np.arange(len(y)), y, label=r\"$\\exp\\left(-\\frac{x}{\\tau}\\right) \\cos x$\")\n",
    "plt.plot(np.arange(len(rnn_res)), rnn_res, label=\"RNN result\")\n",
    "plt.plot(np.arange(len(lstm_res)), lstm_res, label=\"LSTM result\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "減衰振動曲線の場合、今回設定したパラメタでは、LSTMとRNNの差は出ていないようです。ただ、実務レベルでは、RNNよりLSTMの方がより使われており、結果も出ているように思います。今回はただの練習なので、ここで終わりにしようと思います。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
