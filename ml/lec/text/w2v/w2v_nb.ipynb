{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec と doc2vec\n",
    "\n",
    "単語や文章を分散表現（意味が似たような単語や文章を似たようなベクトルとして表現）を取得します。\n",
    "\n",
    "### github\n",
    "- jupyter notebook形式のファイルは[こちら](https://github.com/hiroshi0530/wa-src/blob/master/ml/lec/text/w2v/w2v_nb.ipynb)\n",
    "\n",
    "### google colaboratory\n",
    "- google colaboratory で実行する場合は[こちら](https://colab.research.google.com/github/hiroshi0530/wa-src/blob/master/ml/lec/text/w2v/w2v_nb.ipynb)\n",
    "\n",
    "### 筆者の環境\n",
    "筆者のOSはmacOSです。LinuxやUnixのコマンドとはオプションが異なります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductName:\tMac OS X\r\n",
      "ProductVersion:\t10.14.6\r\n",
      "BuildVersion:\t18G6032\r\n"
     ]
    }
   ],
   "source": [
    "!sw_vers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的なライブラリをインポートしそのバージョンを確認しておきます。tensorflowとkerasuのversionも確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version : 3.3.2\n",
      "scipy version : 1.5.2\n",
      "numpy version : 1.18.5\n",
      "tensorflow version :  2.3.1\n",
      "keras version :  2.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print('matplotlib version :', matplotlib.__version__)\n",
    "print('scipy version :', scipy.__version__)\n",
    "print('numpy version :', np.__version__)\n",
    "print('tensorflow version : ', tf.__version__)\n",
    "print('keras version : ', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テキストデータの取得\n",
    "\n",
    "著作権の問題がない青空文庫からすべての作品をダウンロードしてきます。gitがかなり重いので、最新の履歴だけを取得します。\n",
    "\n",
    "```bash\n",
    "git clone --depth 1 https://github.com/aozorabunko/aozorabunko.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際のファイルはcardsにzip形式として保存されているようです。ディレクトリの個数を確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19636\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./aozorabunko/cards/* | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zipファイルだけzipsに移動させます。\n",
    "\n",
    "```bash\n",
    "find ./aozorabunko/cards/ -name *.zip | xargs -I{} cp {} -t ./zips/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000_ruby_2956.zip\r\n",
      "1001_ruby_2229.zip\r\n",
      "1002_ruby_20989.zip\r\n",
      "1003_ruby_2008.zip\r\n",
      "1004_ruby_2053.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./zips/ | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16444\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./zips/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となり、16444個のzipファイルがある事が分かります。こちらをすべて解凍し、ディレクトリを移動させます。\n",
    "\n",
    "```bash\n",
    "for i in `ls`; do [[ ${i##*.} == zip ]] && unzip -o $i -d ../texts/; done\n",
    "```\n",
    "\n",
    "これで、textｓというディレクトリにすべての作品のテキストファイルがインストールされました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miyazawa_kenji_zenshu.txt\r\n",
      "miyazawa_kenji_zenshuno_kankoni_saishite.txt\r\n",
      "miyazawa_kenjino_sekai.txt\r\n",
      "miyazawa_kenjino_shi.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./texts/ | grep miyazawa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ginga_tetsudono_yoru.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./texts/ | grep ginga_tetsudo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となり、宮沢賢治関連の作品も含まれていることが分かります。銀河鉄道の夜もあります。\n",
    "\n",
    "## 銀河鉄道の夜を使ったword2vec\n",
    "\n",
    "今回はすべてのテキストファイルを対象にするには時間がかかるので、同じ岩手県出身の、高校の先輩でもある宮沢賢治の作品を例に取りword2vecを試してみます。\n",
    "しかし、ファイルの中身を見てみると、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "��͓S���̖�\r",
      "\r\n",
      "�{�򌫎�\r",
      "\r\n",
      "\r",
      "\r\n",
      "-------------------------------------------------------\r",
      "\r\n",
      "�y�e�L�X�g���Ɍ����L���ɂ��āz\r",
      "\r\n",
      "\r",
      "\r\n",
      "�s�t�F���r\r",
      "\r\n",
      "�i��j�k�\\���s�������ӂ��t\r",
      "\r\n",
      "\r",
      "\r\n",
      "�m���n�F���͎Ғ��@��ɊO���̐�����A�T�_�̈ʒu�̎w��\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head ./texts/ginga_tetsudono_yoru.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift_JIS (CRLF)\r\n"
     ]
    }
   ],
   "source": [
    "!nkf --guess ./texts/ginga_tetsudono_yoru.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となりshift_jisで保存されていることが分かります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nkf -w ./texts/ginga_tetsudono_yoru.txt > ginga.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "と、ディレクトリを変更し、ファイル名も変更します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "銀河鉄道の夜\r",
      "\r\n",
      "宮沢賢治\r",
      "\r\n",
      "\r",
      "\r\n",
      "-------------------------------------------------------\r",
      "\r\n",
      "【テキスト中に現れる記号について】\r",
      "\r\n",
      "\r",
      "\r\n",
      "《》：ルビ\r",
      "\r\n",
      "（例）北十字《きたじふじ》\r",
      "\r\n",
      "\r",
      "\r\n",
      "［＃］：入力者注　主に外字の説明や、傍点の位置の指定\r",
      "\r\n",
      "　　　（数字は、JIS X 0213の面区点番号またはUnicode、底本のページと行数）\r",
      "\r\n",
      "（例）※［＃小書き片仮名ヰ、155-15］\r",
      "\r\n",
      "\r",
      "\r\n",
      "　［＃（…）］：訓点送り仮名\r",
      "\r\n",
      "　（例）僕［＃（ん）］とこ\r",
      "\r\n",
      "-------------------------------------------------------\r",
      "\r\n",
      "\r",
      "\r\n",
      "［＃７字下げ］一、午后の授業［＃「一、午后の授業」は中見出し］\r",
      "\r\n",
      "\r",
      "\r\n",
      "「ではみなさんは、さういふふうに川だと云はれたり、乳の流れたあとだと云はれたりしてゐたこのぼんやりと白いものがほんたうは何かご承知ですか。」先生は、黒板に吊した大きな黒い星座の図の、上から下へ白くけぶった銀河帯のやうなところを指しながら、みんなに問をかけました。\r",
      "\r\n",
      "カムパネルラが手をあげました。それから四五人手をあげました。ジョバンニも手をあげやうとして、急いでそのまゝやめました。たしかにあれがみんな星だと、いつか雑誌で読んだのでしたが、このごろはジョバンニはまるで毎日教室でもねむく、本を読むひまも読む本もないので、なんだかどんなこともよくわからないといふ気持ちがするのでした。\r",
      "\r\n",
      "ところが先生は早くもそれを見附けたのでした。\r",
      "\r\n",
      "「ジョバンニさん。あなたはわかってゐるのでせう。」\r",
      "\r\n",
      "ジョバンニは勢よく立ちあがりましたが、立って見るともうはっきりとそれを答へることができないのでした。ザネリが前の席からふりかへって、ジョバンニを見てくすっとわらひました。ジョバンニはもうどぎまぎしてまっ赤になってしまひました。先生がまた云ひました。\r",
      "\r\n",
      "「大きな望遠鏡で銀河をよっく調べると銀河は大体何でせう。」\r",
      "\r\n",
      "cat: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!cat ginga.txt | head -n 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ジョバンニはそのカムパネルラはもうあの銀河のはづれにしかゐないといふやうな気がしてしかたなかったのです。\r",
      "\r\n",
      "けれどもみんなはまだ、どこかの波の間から、\r",
      "\r\n",
      "「ぼくずゐぶん泳いだぞ。」と云ひながらカムパネルラが出て来るか或ひはカムパネルラがどこかの人の知らない洲にでも着いて立ってゐて誰かの来るのを待ってゐるかといふやうな気がして仕方ないらしいのでした。けれども俄かにカムパネルラのお父さんがきっぱり云ひました。\r",
      "\r\n",
      "「もう駄目です。落ちてから四十五分たちましたから。」\r",
      "\r\n",
      "ジョバンニは思はずか〔け〕よって博士の前に立って、ぼくはカムパネルラの行った方を知ってゐますぼくはカムパネルラといっしょに歩いてゐたのですと云はうとしましたがもうのどがつまって何とも云へませんでした。すると博士はジョバンニが挨拶に来たとでも思ったものですか　しばらくしげしげジョバンニを見てゐましたが\r",
      "\r\n",
      "「あなたはジョバンニさんでしたね。どうも今晩はありがたう。」と叮ねいに云ひました。\r",
      "\r\n",
      "　ジョバンニは何も云へずにたゞおじぎをしました。\r",
      "\r\n",
      "「あなたのお父さんはもう帰ってゐますか。」博士は堅く時計を握ったまゝまたきゝました。\r",
      "\r\n",
      "「いゝえ。」ジョバンニはかすかに頭をふりました。\r",
      "\r\n",
      "「どうしたのかなあ、ぼくには一昨日大へん元気な便りがあったんだが。今日あ〔〕たりもう着くころなんだが。船が遅れたんだな。ジョバンニさん。あした放課后みなさんとうちへ遊びに来てくださいね。」\r",
      "\r\n",
      "さう云ひながら博士は〔〕また川下の銀河のいっぱいにうつった方へじっと眼を送りました。ジョバンニはもういろいろなことで胸がいっぱいでなんにも云へずに博士の前をはなれて早くお母さんに牛乳を持って行ってお父さんの帰ることを知らせやうと思ふともう一目散に河原を街の方へ走りました。\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "底本：「【新】校本宮澤賢治全集　第十一巻　童話※［＃ローマ数字4、1-13-24］　本文篇」筑摩書房\r",
      "\r\n",
      "　　　1996（平成8）年1月25日初版第1刷発行\r",
      "\r\n",
      "※底本のテキストは、著者草稿によります。\r",
      "\r\n",
      "※底本では校訂及び編者による説明を「〔　〕」、削除を「〔〕」で表示しています。\r",
      "\r\n",
      "※「カムパネルラ」と「カンパネルラ」の混在は、底本通りです。\r",
      "\r\n",
      "※底本は新字旧仮名づかいです。なお拗音、促音の小書きは、底本通りです。\r",
      "\r\n",
      "入力：砂場清隆\r",
      "\r\n",
      "校正：北川松生\r",
      "\r\n",
      "2016年6月10日作成\r",
      "\r\n",
      "青空文庫作成ファイル：\r",
      "\r\n",
      "このファイルは、インターネットの図書館、青空文庫（http://www.aozora.gr.jp/）で作られました。入力、校正、制作にあたったのは、ボランティアの皆さんです。\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat ginga.txt | tail -n 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となり、ファイルの先頭と、末尾に参考情報が載っているほかは、ちゃんとテキストとしてデータが取れている模様です。\n",
    "先ず、この辺の前処理を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('ginga.txt', mode='r') as f:\n",
    "  all_sentence = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全角、半角の空白、改行コード、縦線(|)をすべて削除します。正規表現を利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence = all_sentence.replace(\" \", \"\").replace(\"　\",\"\").replace(\"\\n\",\"\").replace(\"|\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《》で囲まれたルビの部分を削除します。正規表現を利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence = re.sub(\"《[^》]+》\", \"\", all_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------の部分で分割を行い、2番目の要素を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_sentence = re.split(\"\\-{8,}\", all_sentence)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "。で分割し、文ごとにリストに格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['［＃７字下げ］一、午后の授業［＃「一、午后の授業」は中見出し］「ではみなさんは、さういふふうに川だと云はれたり、乳の流れたあとだと云はれたりしてゐたこのぼんやりと白いものがほんたうは何かご承知ですか。',\n",
       " '」先生は、黒板に吊した大きな黒い星座の図の、上から下へ白くけぶった銀河帯のやうなところを指しながら、みんなに問をかけました。',\n",
       " 'カムパネルラが手をあげました。',\n",
       " 'それから四五人手をあげました。',\n",
       " 'ジョバンニも手をあげやうとして、急いでそのまゝやめました。']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list = all_sentence.split(\"。\")\n",
    "sentence_list = [ s + \"。\" for s in sentence_list]\n",
    "sentence_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初の文は不要なので削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['」先生は、黒板に吊した大きな黒い星座の図の、上から下へ白くけぶった銀河帯のやうなところを指しながら、みんなに問をかけました。',\n",
       " 'カムパネルラが手をあげました。',\n",
       " 'それから四五人手をあげました。',\n",
       " 'ジョバンニも手をあげやうとして、急いでそのまゝやめました。',\n",
       " 'たしかにあれがみんな星だと、いつか雑誌で読んだのでしたが、このごろはジョバンニはまるで毎日教室でもねむく、本を読むひまも読む本もないので、なんだかどんなこともよくわからないといふ気持ちがするのでした。']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list = sentence_list[1:]\n",
    "sentence_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となり、不要な部分を削除し、一文ごとにリストに格納できました。前処理は終了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## janomeによる形態素解析\n",
    "\n",
    "janomeは日本語の文章を形態素ごとに分解する事が出来るツールです。同じようなツールとして、MecabやGinzaなどがあります。一長一短があると思いますが、ここではjanomeを利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['先生', '黒板', '吊す', '星座', '図', '上', '下', 'けぶる', '銀河', '帯']\n"
     ]
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "word_list = []\n",
    "# word_per_sentence_list = []\n",
    "# for sentence in sentence_list:\n",
    "#   word_list.extend(list(t.tokenize(sentence, wakati=True)))\n",
    "#   word_per_sentence_list.append(list(t.tokenize(sentence, wakati=True)))\n",
    "\n",
    "# テキストを引数として、形態素解析の結果、名詞・動詞・形容詞(原形)のみを配列で抽出する関数を定義 \n",
    "def extract_words(text):\n",
    "  tokens = t.tokenize(text)\n",
    "  return [token.base_form for token in tokens if token.part_of_speech.split(',')[0] in['名詞', '動詞']]\n",
    "    \n",
    "\n",
    "#  関数テスト\n",
    "# ret = extract_words('三四郎は京都でちょっと用があって降りたついでに。')\n",
    "# for word in ret:\n",
    "#    print(word)\n",
    "\n",
    "# 全体のテキストを句点('。')で区切った配列にする。 \n",
    "# sentences = text.split('。')\n",
    "# それぞれの文章を単語リストに変換(処理に数分かかります)\n",
    "# word_list = [extract_words(sentence) for sentence in sentence_list] \n",
    "for sentence in sentence_list:\n",
    "  word_list.extend(extract_words(sentence))\n",
    "print(word_list[:10])\n",
    "# print(word_per_sentence_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語のカウント\n",
    "\n",
    "単語のカウントを行い、出現頻度の高いベスト10を抽出してみます。名詞のみに限定した方が良かったかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "count = collections.Counter(word_list)\n",
    "count.most_common()[:10]\n",
    "dict(count.most_common())['銀河']\n",
    "dict(count.most_common())['ジョバンニ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gensimに含まれるword2vecを用いた学習\n",
    "\n",
    "word2vecを用いて、word_listの分散表現を取得します。使い方はいくらでも検索できますので、ここでは割愛します。単語のリストを渡せば、ほぼ自動的に分散表現を作ってくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['先生',\n",
       " '黒板',\n",
       " '吊す',\n",
       " '星座',\n",
       " '図',\n",
       " '上',\n",
       " '下',\n",
       " 'けぶる',\n",
       " '銀河',\n",
       " '帯',\n",
       " 'やう',\n",
       " 'ところ',\n",
       " '指す',\n",
       " 'みんな',\n",
       " '問',\n",
       " 'かける',\n",
       " 'カムパネルラ',\n",
       " '手',\n",
       " 'あげる',\n",
       " '四',\n",
       " '五',\n",
       " '人',\n",
       " '手',\n",
       " 'あげる',\n",
       " 'ジョバンニ',\n",
       " '手',\n",
       " 'あげる',\n",
       " 'やう',\n",
       " '急ぐ',\n",
       " 'やめる',\n",
       " 'あれ',\n",
       " 'みんな',\n",
       " '星',\n",
       " 'いつか',\n",
       " '雑誌',\n",
       " '読む',\n",
       " 'の',\n",
       " 'このごろ',\n",
       " 'ジョバンニ',\n",
       " '毎日',\n",
       " '教室',\n",
       " '本',\n",
       " '読む',\n",
       " 'ひま',\n",
       " '読む',\n",
       " '本',\n",
       " 'こと',\n",
       " 'わかる',\n",
       " '気持ち',\n",
       " 'する',\n",
       " 'の',\n",
       " '先生',\n",
       " 'それ',\n",
       " '見る',\n",
       " '附ける',\n",
       " 'の',\n",
       " 'ジョバンニ',\n",
       " 'さん',\n",
       " 'あなた',\n",
       " 'わかる',\n",
       " 'ゐる',\n",
       " 'する',\n",
       " 'ジョバンニ',\n",
       " '勢',\n",
       " '立ちあがる',\n",
       " '立つ',\n",
       " '見る',\n",
       " 'それ',\n",
       " '答',\n",
       " 'へる',\n",
       " 'こと',\n",
       " 'できる',\n",
       " 'の',\n",
       " 'ザネリ',\n",
       " '前',\n",
       " '席',\n",
       " 'ふり',\n",
       " 'ジョバンニ',\n",
       " '見る',\n",
       " 'く',\n",
       " 'わら',\n",
       " 'ひる',\n",
       " 'ジョバンニ',\n",
       " 'どぎまぎ',\n",
       " 'する',\n",
       " '赤',\n",
       " 'なる',\n",
       " 'しまふ',\n",
       " '先生',\n",
       " '云',\n",
       " 'ひる',\n",
       " '望遠鏡',\n",
       " '銀河',\n",
       " 'よる',\n",
       " 'くる',\n",
       " '調べる',\n",
       " '銀河',\n",
       " '大体',\n",
       " 'する',\n",
       " '星',\n",
       " 'ジョバンニ',\n",
       " '思ふ',\n",
       " 'こんど',\n",
       " '答',\n",
       " 'へる',\n",
       " 'こと',\n",
       " 'できる',\n",
       " '先生',\n",
       " '困る',\n",
       " 'やう',\n",
       " 'する',\n",
       " '眼',\n",
       " 'カムパネルラ',\n",
       " '方',\n",
       " '向ける',\n",
       " 'カムパネルラ',\n",
       " 'さん',\n",
       " '名指す',\n",
       " '元気',\n",
       " '手',\n",
       " 'あげる',\n",
       " 'カムパネルラ',\n",
       " 'ぢ',\n",
       " 'ぢ',\n",
       " '立ち上る',\n",
       " '答',\n",
       " 'できる',\n",
       " '先生',\n",
       " '意外',\n",
       " 'やう',\n",
       " 'ぢ',\n",
       " 'カムパネルラ',\n",
       " '見る',\n",
       " 'ゐる',\n",
       " '急ぐ',\n",
       " '云',\n",
       " 'ひる',\n",
       " '自分',\n",
       " '星図',\n",
       " '指す',\n",
       " 'ぼんやり',\n",
       " '銀河',\n",
       " '望遠鏡',\n",
       " '見る',\n",
       " 'たくさん',\n",
       " '星',\n",
       " '見える',\n",
       " 'の',\n",
       " 'ジョバンニ',\n",
       " 'さん',\n",
       " 'する',\n",
       " 'する',\n",
       " 'ジョバンニ',\n",
       " '赤',\n",
       " 'なる',\n",
       " 'うなづく',\n",
       " 'いつか',\n",
       " 'ジョバンニ',\n",
       " '眼',\n",
       " 'なか',\n",
       " '涙',\n",
       " 'なる',\n",
       " 'する',\n",
       " '僕',\n",
       " '知る',\n",
       " 'ゐる',\n",
       " 'の',\n",
       " 'カムパネルラ',\n",
       " '知る',\n",
       " 'ゐる',\n",
       " 'それ',\n",
       " 'いつか',\n",
       " 'カムパネルラ',\n",
       " 'お父さん',\n",
       " '博士',\n",
       " 'うち',\n",
       " 'カムパネルラ',\n",
       " 'いっしょ',\n",
       " '読む',\n",
       " '雑誌',\n",
       " 'なか',\n",
       " 'ある',\n",
       " 'の',\n",
       " 'それ',\n",
       " 'どこ',\n",
       " 'カムパネルラ',\n",
       " '雑誌',\n",
       " '読む',\n",
       " 'お父さん',\n",
       " '書',\n",
       " '斎',\n",
       " '巨',\n",
       " '本',\n",
       " 'もつ',\n",
       " 'くる',\n",
       " 'ぎん',\n",
       " 'ところ',\n",
       " 'ひろげる',\n",
       " 'まっ黒',\n",
       " '頁',\n",
       " 'いっぱい',\n",
       " '点々',\n",
       " 'ある',\n",
       " '写真',\n",
       " '二',\n",
       " '人',\n",
       " 'いつ',\n",
       " '見る',\n",
       " 'の',\n",
       " 'それ',\n",
       " 'カムパネルラ',\n",
       " '忘れる',\n",
       " '筈',\n",
       " '返事',\n",
       " 'する',\n",
       " 'の',\n",
       " 'このごろ',\n",
       " 'ぼく',\n",
       " '朝',\n",
       " '午后',\n",
       " '仕事',\n",
       " '学校',\n",
       " '出る',\n",
       " 'みんな',\n",
       " '遊ぶ',\n",
       " 'カムパネルラ',\n",
       " '物',\n",
       " '云',\n",
       " 'やう',\n",
       " 'なる',\n",
       " 'カムパネルラ',\n",
       " 'それ',\n",
       " '知る',\n",
       " '気の毒',\n",
       " 'がる',\n",
       " '返事',\n",
       " 'する',\n",
       " 'の',\n",
       " '考へる',\n",
       " 'ぶん',\n",
       " 'カムパネルラ',\n",
       " 'あはれ',\n",
       " 'やう',\n",
       " '気',\n",
       " 'する',\n",
       " 'の',\n",
       " '先生',\n",
       " '云',\n",
       " 'ひる',\n",
       " '天の川',\n",
       " 'ほん',\n",
       " 'うに',\n",
       " '川',\n",
       " '考へる',\n",
       " '一つ',\n",
       " '一つ',\n",
       " '星',\n",
       " 'みんな',\n",
       " '川',\n",
       " 'そこ',\n",
       " '砂',\n",
       " '砂利',\n",
       " '粒',\n",
       " 'あたる',\n",
       " 'わけ',\n",
       " 'これ',\n",
       " '巨',\n",
       " '乳',\n",
       " '流れ',\n",
       " '考へる',\n",
       " '天の川',\n",
       " '似る',\n",
       " 'ゐる',\n",
       " '星',\n",
       " 'みな',\n",
       " '乳',\n",
       " 'なか',\n",
       " '細か',\n",
       " 'うかぶ',\n",
       " 'ゐる',\n",
       " '脂',\n",
       " '油',\n",
       " '球',\n",
       " 'あたる',\n",
       " 'の',\n",
       " 'そん',\n",
       " '何',\n",
       " '川',\n",
       " '水',\n",
       " 'あたる',\n",
       " '云',\n",
       " 'ひる',\n",
       " 'それ',\n",
       " '真空',\n",
       " '光',\n",
       " 'ある',\n",
       " 'さ',\n",
       " '伝へる',\n",
       " 'もの',\n",
       " '太陽',\n",
       " '地球',\n",
       " 'なか',\n",
       " '浮ぶ',\n",
       " 'ゐる',\n",
       " 'の',\n",
       " 'つまり',\n",
       " '私',\n",
       " 'ども',\n",
       " '天の川',\n",
       " '水',\n",
       " 'なか',\n",
       " '棲む',\n",
       " 'ゐる',\n",
       " 'わけ',\n",
       " '天の川',\n",
       " '水',\n",
       " 'なか',\n",
       " '四方',\n",
       " '見る',\n",
       " 'ちゃう',\n",
       " '水',\n",
       " '見える',\n",
       " 'やう',\n",
       " '天の川',\n",
       " '底',\n",
       " 'ところ',\n",
       " '星',\n",
       " 'たくさん',\n",
       " '集う',\n",
       " '見え',\n",
       " 'ぼんやり',\n",
       " '見える',\n",
       " 'の',\n",
       " '模型',\n",
       " 'ごらん',\n",
       " 'なさる',\n",
       " '先生',\n",
       " '中',\n",
       " 'たくさん',\n",
       " '光る',\n",
       " '砂',\n",
       " 'つぶ',\n",
       " '入る',\n",
       " '両面',\n",
       " '凸レンズ',\n",
       " '指す',\n",
       " '天の川',\n",
       " '形',\n",
       " 'ちゃう',\n",
       " 'こんな',\n",
       " 'の',\n",
       " 'いちいち',\n",
       " '光る',\n",
       " 'つぶ',\n",
       " 'みんな',\n",
       " '私',\n",
       " 'ども',\n",
       " '太陽',\n",
       " 'やう',\n",
       " 'ぶん',\n",
       " '光る',\n",
       " 'ゐる',\n",
       " '星',\n",
       " '考へる',\n",
       " '私',\n",
       " 'ども',\n",
       " '太陽',\n",
       " 'ほる',\n",
       " '中ごろ',\n",
       " 'ある',\n",
       " '地球',\n",
       " '近く',\n",
       " 'ある',\n",
       " 'する',\n",
       " 'みなさん',\n",
       " '夜',\n",
       " 'まん中',\n",
       " '立つ',\n",
       " 'レンズ',\n",
       " '中',\n",
       " '見る',\n",
       " 'はする',\n",
       " 'ごらん',\n",
       " 'なさる',\n",
       " 'こっち',\n",
       " '方',\n",
       " 'レンズ',\n",
       " 'づく',\n",
       " '光る',\n",
       " '粒',\n",
       " '星',\n",
       " '見える',\n",
       " 'する',\n",
       " 'こっち',\n",
       " 'こっち',\n",
       " '方',\n",
       " 'ガラス',\n",
       " '光る',\n",
       " '粒',\n",
       " '星',\n",
       " 'たくさん',\n",
       " '見える',\n",
       " 'の',\n",
       " '見える',\n",
       " 'これ',\n",
       " '今日',\n",
       " '銀河',\n",
       " '説',\n",
       " 'の',\n",
       " 'そん',\n",
       " 'レンズ',\n",
       " 'さ',\n",
       " 'どれ',\n",
       " '位',\n",
       " 'ある',\n",
       " '中',\n",
       " 'さまざま',\n",
       " '星',\n",
       " '時間',\n",
       " '次',\n",
       " '理科',\n",
       " '時間',\n",
       " 'お話',\n",
       " 'する',\n",
       " '今日',\n",
       " '銀河',\n",
       " 'お祭',\n",
       " 'の',\n",
       " 'みなさん',\n",
       " '外',\n",
       " 'でる',\n",
       " 'ごらん',\n",
       " 'なさる',\n",
       " 'こ',\n",
       " '本',\n",
       " 'ノート',\n",
       " 'おす',\n",
       " 'まひ',\n",
       " 'なさる',\n",
       " '教室',\n",
       " '中',\n",
       " '机',\n",
       " '蓋',\n",
       " 'あける',\n",
       " 'しめる',\n",
       " '本',\n",
       " '重ねる',\n",
       " 'する',\n",
       " '音',\n",
       " 'みんな',\n",
       " '立つ',\n",
       " '礼',\n",
       " 'する',\n",
       " '教室',\n",
       " '出る',\n",
       " '＃',\n",
       " '７',\n",
       " '字',\n",
       " '下げ',\n",
       " '二',\n",
       " '活版',\n",
       " '所',\n",
       " '＃「〔',\n",
       " '二',\n",
       " '活版',\n",
       " '所',\n",
       " '見出し',\n",
       " 'ジョバンニ',\n",
       " '学校',\n",
       " '門',\n",
       " '出る',\n",
       " 'とき',\n",
       " '組',\n",
       " '七',\n",
       " '八',\n",
       " '人',\n",
       " '家',\n",
       " '帰る',\n",
       " 'カムパネルラ',\n",
       " 'まん中',\n",
       " 'する',\n",
       " '校庭',\n",
       " '隅',\n",
       " '桜',\n",
       " '木',\n",
       " 'ところ',\n",
       " '集まる',\n",
       " 'ゐる',\n",
       " 'それ',\n",
       " 'こむ',\n",
       " '星祭',\n",
       " 'あかり',\n",
       " 'こしらえる',\n",
       " '川',\n",
       " '流す',\n",
       " '烏瓜',\n",
       " '取る',\n",
       " '行く',\n",
       " '相談',\n",
       " 'の',\n",
       " 'ジョバンニ',\n",
       " '手',\n",
       " '振る',\n",
       " '学校',\n",
       " '門',\n",
       " '出る',\n",
       " '来る',\n",
       " '町',\n",
       " '家々',\n",
       " 'はこぶ',\n",
       " '銀河',\n",
       " '祭り',\n",
       " 'いち',\n",
       " 'ゐる',\n",
       " '葉',\n",
       " '玉',\n",
       " 'つるす',\n",
       " 'ひのき',\n",
       " '枝',\n",
       " 'あかり',\n",
       " 'つける',\n",
       " 'いろいろ',\n",
       " '仕度',\n",
       " 'する',\n",
       " 'ゐる',\n",
       " 'の',\n",
       " '家',\n",
       " '帰る',\n",
       " 'ジョバンニ',\n",
       " '町',\n",
       " '三つ',\n",
       " '曲る',\n",
       " 'ある',\n",
       " '活版',\n",
       " '処',\n",
       " 'いう',\n",
       " '入口',\n",
       " '計算',\n",
       " '台',\n",
       " '居る',\n",
       " 'だぶだぶ',\n",
       " 'シャツ',\n",
       " '着る',\n",
       " '人',\n",
       " 'おじぎ',\n",
       " 'する',\n",
       " 'ジョバンニ',\n",
       " '靴',\n",
       " 'ぬぐ',\n",
       " '上る',\n",
       " '突き当り',\n",
       " '扉',\n",
       " 'あける',\n",
       " '中',\n",
       " '昼',\n",
       " '電',\n",
       " '燈',\n",
       " 'つく',\n",
       " 'たくさん',\n",
       " '輪',\n",
       " '転',\n",
       " '器',\n",
       " 'ば',\n",
       " 'とむ',\n",
       " 'はる',\n",
       " 'きれる',\n",
       " '頭',\n",
       " 'しばる',\n",
       " 'ラムプ',\n",
       " '［＃「',\n",
       " 'ラムプ',\n",
       " '傍線',\n",
       " 'シェード',\n",
       " 'かける',\n",
       " 'する',\n",
       " '人',\n",
       " 'たち',\n",
       " '何',\n",
       " '歌',\n",
       " 'ふる',\n",
       " 'やう',\n",
       " '読む',\n",
       " '数',\n",
       " 'する',\n",
       " 'たくさん',\n",
       " '働く',\n",
       " '居る',\n",
       " 'ジョバンニ',\n",
       " '入口',\n",
       " '三',\n",
       " '番目',\n",
       " '卓子',\n",
       " '座る',\n",
       " '人',\n",
       " '所',\n",
       " '行く',\n",
       " 'おじぎ',\n",
       " 'する',\n",
       " '人',\n",
       " '棚',\n",
       " 'さがす',\n",
       " 'これ',\n",
       " '拾う',\n",
       " '行ける',\n",
       " '云',\n",
       " 'ひる',\n",
       " '一',\n",
       " '枚',\n",
       " '紙切れ',\n",
       " '渡す',\n",
       " 'ジョバンニ',\n",
       " '人',\n",
       " '卓子',\n",
       " '足もと',\n",
       " '一つ',\n",
       " '函',\n",
       " 'とりだす',\n",
       " 'ふる',\n",
       " 'の',\n",
       " '電',\n",
       " '燈',\n",
       " 'たくさん',\n",
       " 'つく',\n",
       " 'たてかける',\n",
       " 'ある',\n",
       " '壁',\n",
       " '隅',\n",
       " '所',\n",
       " 'しゃがむ',\n",
       " '込む',\n",
       " 'ピンセット',\n",
       " '粟粒',\n",
       " 'ぐらゐの',\n",
       " '活字',\n",
       " '次',\n",
       " '次',\n",
       " '拾',\n",
       " 'ひる',\n",
       " 'はじめる',\n",
       " '胸',\n",
       " 'あて',\n",
       " 'する',\n",
       " '人',\n",
       " 'ジョバンニ',\n",
       " 'うし',\n",
       " 'ろ',\n",
       " '通る',\n",
       " 'よう',\n",
       " '虫めがね',\n",
       " '君',\n",
       " '云',\n",
       " 'ひる',\n",
       " '近く',\n",
       " '四',\n",
       " '五',\n",
       " '人',\n",
       " '人',\n",
       " 'たち',\n",
       " '声',\n",
       " 'たてる',\n",
       " 'こっち',\n",
       " '向く',\n",
       " '冷',\n",
       " 'く',\n",
       " 'わら',\n",
       " 'ひる',\n",
       " 'ジョバンニ',\n",
       " '何',\n",
       " 'ん',\n",
       " '眼',\n",
       " '拭',\n",
       " 'ひる',\n",
       " '活字',\n",
       " 'ひろ',\n",
       " 'ひる',\n",
       " '六',\n",
       " '時',\n",
       " 'うる',\n",
       " 'たつ',\n",
       " 'ころ',\n",
       " 'ジョバンニ',\n",
       " '拾う',\n",
       " '活字',\n",
       " '入れる',\n",
       " '箱',\n",
       " 'いちど',\n",
       " '手',\n",
       " 'もつ',\n",
       " '紙きれ',\n",
       " '引き合せる',\n",
       " 'さっき',\n",
       " '卓子',\n",
       " '人',\n",
       " '持つ',\n",
       " '来る',\n",
       " '人',\n",
       " '黙る',\n",
       " 'それ',\n",
       " '受け取る',\n",
       " '微か',\n",
       " 'うなづく',\n",
       " 'ジョバンニ',\n",
       " 'おじぎ',\n",
       " 'する',\n",
       " '扉',\n",
       " 'あける',\n",
       " 'さっき',\n",
       " '計算',\n",
       " '台',\n",
       " 'ところ',\n",
       " '来る',\n",
       " 'さっき',\n",
       " '白',\n",
       " '服',\n",
       " '着る',\n",
       " '人',\n",
       " 'だまる',\n",
       " '銀貨',\n",
       " '一つ',\n",
       " 'ジョバンニ',\n",
       " '渡す',\n",
       " 'ジョバンニ',\n",
       " '俄',\n",
       " '顔',\n",
       " 'いる',\n",
       " 'なる',\n",
       " '威勢',\n",
       " 'おじぎ',\n",
       " 'する',\n",
       " '台の下',\n",
       " '置く',\n",
       " '鞄',\n",
       " 'もつ',\n",
       " 'もてる',\n",
       " '飛びだす',\n",
       " '元気',\n",
       " '口笛',\n",
       " '吹く',\n",
       " 'パン',\n",
       " '屋',\n",
       " '寄る',\n",
       " 'パン',\n",
       " '塊',\n",
       " '一つ',\n",
       " '角砂糖',\n",
       " '一',\n",
       " '袋',\n",
       " '買',\n",
       " 'ひる',\n",
       " '一目散',\n",
       " '走る',\n",
       " 'だす',\n",
       " '＃',\n",
       " '７',\n",
       " '字',\n",
       " '下げ',\n",
       " '三',\n",
       " '家',\n",
       " '［＃「',\n",
       " '三',\n",
       " '家',\n",
       " '見出し',\n",
       " 'ジョバンニ',\n",
       " '勢',\n",
       " '帰る',\n",
       " '来る',\n",
       " 'の',\n",
       " '裏町',\n",
       " '家',\n",
       " '三つ',\n",
       " 'ならぶ',\n",
       " '入口',\n",
       " '一番',\n",
       " '左側',\n",
       " '空',\n",
       " '箱',\n",
       " '紫いろ',\n",
       " 'ケール',\n",
       " 'アスパラガス',\n",
       " '植える',\n",
       " 'ある',\n",
       " '二つ',\n",
       " '窓',\n",
       " '日覆',\n",
       " 'ひる',\n",
       " 'たま',\n",
       " 'なる',\n",
       " 'ゐる',\n",
       " 'お母さん',\n",
       " 'いま',\n",
       " '帰る',\n",
       " '工合',\n",
       " 'ジョバンニ',\n",
       " '靴',\n",
       " 'ぬぐ',\n",
       " '云',\n",
       " 'ひる',\n",
       " 'ジョバンニ',\n",
       " '仕事',\n",
       " '今日',\n",
       " 'わたし',\n",
       " 'はず',\n",
       " 'うつ',\n",
       " '工合',\n",
       " 'がい',\n",
       " 'ジョバンニ',\n",
       " '玄関',\n",
       " '上る',\n",
       " '行く',\n",
       " 'ジョバンニ',\n",
       " 'お母さん',\n",
       " '入口',\n",
       " '室',\n",
       " '巾',\n",
       " '被る',\n",
       " '寝る',\n",
       " 'ゐる',\n",
       " 'の',\n",
       " 'ジョバンニ',\n",
       " '窓',\n",
       " 'あける',\n",
       " 'お母さん',\n",
       " '今日',\n",
       " '角砂糖',\n",
       " '買う',\n",
       " 'くる',\n",
       " '牛乳',\n",
       " '入れる',\n",
       " 'あげる',\n",
       " 'やう',\n",
       " '思う',\n",
       " 'お前',\n",
       " 'さき',\n",
       " 'あがる',\n",
       " 'あたし',\n",
       " 'ん',\n",
       " 'お母さん',\n",
       " '姉さん',\n",
       " 'いつ',\n",
       " '帰る',\n",
       " '三',\n",
       " '時',\n",
       " 'ころ',\n",
       " '帰る',\n",
       " 'みんな',\n",
       " 'そこら',\n",
       " 'する',\n",
       " 'くれる',\n",
       " 'お母さん',\n",
       " '牛乳',\n",
       " '来る',\n",
       " 'ゐる',\n",
       " 'ん',\n",
       " '来る',\n",
       " 'ぼく',\n",
       " '行く',\n",
       " 'とる',\n",
       " '来る',\n",
       " 'やう',\n",
       " 'あたし',\n",
       " 'でる',\n",
       " 'いる',\n",
       " 'ん',\n",
       " 'お前',\n",
       " 'さき',\n",
       " 'あがる',\n",
       " '姉さん',\n",
       " 'トマト',\n",
       " '何',\n",
       " 'こしらえる',\n",
       " 'そこ',\n",
       " '置く',\n",
       " '行く',\n",
       " 'ぼく',\n",
       " 'たべる',\n",
       " 'やう',\n",
       " 'ジョバンニ',\n",
       " '窓',\n",
       " 'ところ',\n",
       " 'トマト',\n",
       " '皿',\n",
       " 'とる',\n",
       " 'パン',\n",
       " 'いっしょ',\n",
       " 'たべる',\n",
       " 'お母さん',\n",
       " 'ぼく',\n",
       " 'お父さん',\n",
       " '帰る',\n",
       " 'くる',\n",
       " '思ふ',\n",
       " 'あたし',\n",
       " 'する',\n",
       " '思ふ',\n",
       " '思ふ',\n",
       " '今朝',\n",
       " '新聞',\n",
       " '今年',\n",
       " '北の方',\n",
       " '漁',\n",
       " 'へん',\n",
       " '書く',\n",
       " 'ある',\n",
       " 'お父さん',\n",
       " '漁',\n",
       " '出る',\n",
       " 'ゐる',\n",
       " 'しれる',\n",
       " '出る',\n",
       " 'ゐる',\n",
       " 'お父さん',\n",
       " '監獄',\n",
       " '入る',\n",
       " 'やう',\n",
       " 'こと',\n",
       " 'する',\n",
       " '筈',\n",
       " 'ん',\n",
       " '前',\n",
       " 'お父さん',\n",
       " '持つ',\n",
       " 'くる',\n",
       " '学校',\n",
       " '寄贈',\n",
       " 'する',\n",
       " '巨',\n",
       " '蟹',\n",
       " '甲',\n",
       " 'ら',\n",
       " 'の',\n",
       " 'なか',\n",
       " 'ひる',\n",
       " '角',\n",
       " '今',\n",
       " 'みんな',\n",
       " '標本',\n",
       " '室',\n",
       " 'ある',\n",
       " 'ん',\n",
       " '六',\n",
       " '年生',\n",
       " '授業',\n",
       " 'とき',\n",
       " '先生',\n",
       " 'はる',\n",
       " 'はる',\n",
       " '教室',\n",
       " '持つ',\n",
       " '行く',\n",
       " '一昨年',\n",
       " '修学旅行',\n",
       " '以下',\n",
       " '数',\n",
       " '文字',\n",
       " '分',\n",
       " '空白',\n",
       " 'お父さん',\n",
       " '次',\n",
       " 'ラッコ',\n",
       " '上着',\n",
       " 'もつ',\n",
       " 'くる',\n",
       " 'みんな',\n",
       " 'ぼく',\n",
       " 'それ',\n",
       " '云',\n",
       " 'ふよ',\n",
       " 'ひやかす',\n",
       " 'やう',\n",
       " '云',\n",
       " 'ふむ',\n",
       " '悪口',\n",
       " '云',\n",
       " 'ふる',\n",
       " 'カムパネルラ',\n",
       " '云',\n",
       " 'カムパネルラ',\n",
       " 'みんな',\n",
       " 'こと',\n",
       " '云',\n",
       " '気の毒',\n",
       " 'さ',\n",
       " 'うに',\n",
       " 'する',\n",
       " 'ゐる',\n",
       " '人',\n",
       " 'うち',\n",
       " 'お父さん',\n",
       " 'ちる',\n",
       " 'ゃうどおまへたちのやうに',\n",
       " 'とき',\n",
       " '友達',\n",
       " 'お父さん',\n",
       " 'ぼく',\n",
       " 'つれる',\n",
       " 'カムパネルラ',\n",
       " 'うち',\n",
       " 'もつれる',\n",
       " '行く',\n",
       " 'ころ',\n",
       " ...]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(word_list, size=100, min_count=5, window=5, iter=1000, sg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分散行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6690906 , -1.8134489 , -0.50446075, ...,  0.22950223,\n",
       "        -0.24067923, -0.45016605],\n",
       "       [-0.0081544 ,  0.88565207, -0.6879916 , ...,  0.37250426,\n",
       "        -0.37231675, -0.23907655],\n",
       "       [-0.06978781, -0.4953329 , -0.1721944 , ..., -0.34273872,\n",
       "        -0.676891  , -0.7721713 ],\n",
       "       ...,\n",
       "       [ 0.09245484, -0.6152532 , -0.20881364, ...,  0.04918382,\n",
       "         0.10831165,  0.15404673],\n",
       "       [ 0.6117021 , -0.9071201 ,  0.8482464 , ...,  0.27837202,\n",
       "         0.4135082 ,  0.03481499],\n",
       "       [-3.1874008 , -0.96890706,  1.3699456 , ..., -1.5262604 ,\n",
       "        -0.79284537, -0.08142332]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分散行列の形状確認\n",
    "\n",
    "443個の単語について、100次元のベクトルが生成されました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 100)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全単語数は、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ですが、word2vecのmin_countを5にしているので、その文単語数が少なくなっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word '銀河' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-eb818cbee18c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'銀河'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word '銀河' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.wv.index2word[:10]\n",
    "print(model.__dict__['wv']['銀河'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6690906 , -1.8134489 , -0.50446075,  1.0823753 ,  1.0012556 ,\n",
       "        0.17782725,  0.39993393, -0.7516008 ,  1.2903652 , -0.79781705,\n",
       "        0.54625   ,  0.18831149, -0.10043006, -0.68015933, -0.22242035,\n",
       "        0.72337776, -0.31982303, -0.9627689 , -0.22933453, -0.04989067,\n",
       "        0.16735213, -0.02974823, -1.3249292 , -0.27127397,  0.42874482,\n",
       "        0.01675199,  0.8601299 , -0.85613954, -0.79393893,  0.12290027,\n",
       "        0.6677782 ,  0.4430345 , -0.15914361,  0.92404836,  0.7163351 ,\n",
       "        0.27910623, -0.09720881,  0.68278235,  1.1329095 , -0.7275171 ,\n",
       "       -0.99282736,  0.09739671,  1.4512872 , -0.29004535,  1.0013556 ,\n",
       "       -0.78484267, -0.44537067, -0.17693432,  0.00596993, -0.2871559 ,\n",
       "       -1.0671868 ,  0.35299167,  0.6387847 , -1.3476065 , -0.51196575,\n",
       "       -0.09386528,  0.45643848,  0.6014701 , -0.29185364, -0.6555386 ,\n",
       "        0.3910473 , -0.324209  , -0.5417036 ,  0.08710421, -1.1519334 ,\n",
       "        0.08187845,  0.7924016 , -0.00519154, -0.2600619 ,  0.96227944,\n",
       "       -0.12906776,  0.5477753 , -1.1792823 ,  0.20154633, -0.7700448 ,\n",
       "        1.0795287 ,  0.538111  ,  0.24918164,  0.48424342, -0.22555429,\n",
       "       -0.46567798,  0.2812898 ,  0.6985383 ,  1.2283741 ,  1.0126857 ,\n",
       "        0.4486654 , -1.0553776 ,  0.07277382, -0.3959616 , -0.9007682 ,\n",
       "        0.2317583 ,  0.82350373,  0.42838004,  1.0937254 , -0.36720416,\n",
       "        1.062953  ,  0.7355613 ,  0.22950223, -0.24067923, -0.45016605],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word '銀河' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-7276877cfefc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"銀河\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word '銀河' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.wv.__getitem__(\"銀河\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cos類似度による単語抽出\n",
    "\n",
    "ベクトルの内積を計算することにより、指定した単語に類似した単語をその$\\cos$の値と一緒に抽出する事ができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word '銀河' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-081816b8f0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"銀河\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"本\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ジョバンニ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word '銀河' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"銀河\"))\n",
    "print(model.wv.most_similar(\"本\"))\n",
    "print(model.wv.most_similar(\"ジョバンニ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語ベクトルによる演算\n",
    "\n",
    "足し算するにはpositiveメソッドを引き算にはnegativeメソッドを利用します。\n",
    "\n",
    "まず、銀河＋男を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[\"銀河\", \"ジョバンニ\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に銀河＋ジョバンニー家を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[\"銀河\", \"ジョバンニ\"], negative=[\"家\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec\n",
    "\n",
    "文章毎にタグ付けされたTaggedDocumentを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "tagged_doc_list = []\n",
    "\n",
    "for i, sentence in enumerate(word_per_sentence_list):\n",
    "  tagged_doc_list.append(TaggedDocument(sentence, [i]))\n",
    "\n",
    "print(tagged_doc_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents=tagged_doc_list, vector_size=100, min_count=5, window=5, epochs=20, dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_per_sentence_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.docvecs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most_similarで類似度が高い文章のIDと類似度を取得することが出来ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.docvecs.most_similar(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.docvecs.most_similar(0):\n",
    "  print(word_per_sentence_list[p[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感覚的ですが、似たような文章が抽出されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
